{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fh3PmurW-WFG"
   },
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRVDUu5nMiQk",
    "outputId": "f8214e1a-c902-4d4c-bb49-2e93fe1d1548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yahoo_fin in c:\\users\\mlech\\anaconda3\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: requests-html in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (0.10.0)\n",
      "Requirement already satisfied: feedparser in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (6.0.10)\n",
      "Requirement already satisfied: requests in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (2.28.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (1.4.4)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from feedparser->yahoo_fin) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (1.23.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (2022.12.7)\n",
      "Requirement already satisfied: pyquery in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (2.0.0)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.1.3)\n",
      "Requirement already satisfied: parse in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.19.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (0.0.1)\n",
      "Requirement already satisfied: w3lib in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.21.0)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.0.2)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.11.3)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (8.2.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.64.1)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (10.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->yahoo_fin) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from bs4->requests-html->yahoo_fin) (4.11.1)\n",
      "Requirement already satisfied: importlib-resources>=5.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from fake-useragent->requests-html->yahoo_fin) (5.12.0)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyquery->requests-html->yahoo_fin) (4.9.1)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyquery->requests-html->yahoo_fin) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests-html->yahoo_fin) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->requests-html->yahoo_fin) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yahoo_fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6Mb-Apq5M02C"
   },
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AROMFS4N-jot",
    "outputId": "70855e4a-02ed-43bf-993c-8f84c90fe451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days in future that result is calculated: 252\n",
      "reversion_low_value: 12\n",
      "reversion_high_value: 20\n",
      "optimization_max_epochs: 5\n",
      "optimization_max_hidden_layers: 5\n",
      "BEGIN PROCESS\n",
      "latest_date: 2000-01-03 00:00:00\n",
      "OUTPUT COUNT: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_20876\\4089011593.py:185: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[input_symbol_03+'_future_result'][i] = ((df[col03][i+days_in_future_that_result_is_calculated]-df[col03][i])/df[col03][i])\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_20876\\4089011593.py:171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[input_symbol_01+'_percentage'][i] = ((df[col01][i]) - (df[col01][i-days_looking_back])) / (df[col01][i-days_looking_back])\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_20876\\4089011593.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[input_symbol_01+'_percentage_boolean'][i] = 1\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_20876\\4089011593.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[input_symbol_02+'_percentage'][i] = ((df[col02][i]) - (df[col02][i-days_looking_back])) / (df[col02][i-days_looking_back])\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_20876\\4089011593.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[input_symbol_02+'_percentage_boolean'][i] = 1\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_20876\\4089011593.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[input_symbol_01+'_percentage_boolean'][i] = 0\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_20876\\4089011593.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[input_symbol_02+'_percentage_boolean'][i] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_column_list_for_X: ['^GSPC_close', '^DJI_close']\n",
      "output_col_for_y: ['SPY_future_result_boolean']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_20876\\4089011593.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[input_symbol_03+'_future_result_boolean'][i] = 0\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_20876\\4089011593.py:232: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[input_symbol_03+'_future_result_boolean'][i] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_31 (Dense)            (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51 (204.00 Byte)\n",
      "Trainable params: 51 (204.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20876\\4089011593.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    330\u001b[0m           \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m           \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m           \u001b[0mfit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m           \u001b[1;31m# Evaluate the model using the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1781\u001b[0m                         ):\n\u001b[0;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1783\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1784\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m         \u001b[1;31m# no_variable_creation function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m         return tracing_compilation.call_function(\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m   )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1263\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1264\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[0mflat_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[0;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mcall_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1479\u001b[1;33m       outputs = execute.execute(\n\u001b[0m\u001b[0;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     ]\n\u001b[1;32m---> 60\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# ***************************\n",
    "# ***                     ***\n",
    "# ***    SET VARIABLES    ***\n",
    "# ***                     ***\n",
    "# ***************************\n",
    "\n",
    "days_in_future_that_result_is_calculated = 252\n",
    "print(f\"Days in future that result is calculated: {days_in_future_that_result_is_calculated}\")\n",
    "\n",
    "reversion_low_value = 12\n",
    "print(f\"reversion_low_value: {reversion_low_value}\")\n",
    "\n",
    "reversion_high_value = 20\n",
    "print(f\"reversion_high_value: {reversion_high_value}\")\n",
    "\n",
    "optimization_max_epochs = 5\n",
    "print(f\"optimization_max_epochs: {optimization_max_epochs}\")\n",
    "\n",
    "# Max 10:\n",
    "optimization_max_hidden_layers = 5\n",
    "print(f\"optimization_max_hidden_layers: {optimization_max_hidden_layers}\")\n",
    "\n",
    "optimization_max_nodes = 5\n",
    "\n",
    "\n",
    "activation_type = 'relu'\n",
    "\n",
    "# Max 10:\n",
    "num_layers = 2\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "num_nodes = 5\n",
    "\n",
    "\n",
    "# SCALE THE DATA? \"Y\" or \"N\":\n",
    "scale_data = \"Y\"\n",
    "\n",
    "\n",
    "# TICKER SYMBOLS TO PROCESS:\n",
    "\n",
    "# 21 symbols to pair up, plus 2 result tickers to test output,\n",
    "# so 210 unique pairs * 2 outputs = 420 combinations are \n",
    "# looped through and be tested\n",
    "\n",
    "symbol_eval_list = [\n",
    "                        '^GSPC',\n",
    "                        '^DJI',\n",
    "                        '^IXIC',\n",
    "                        '^RUT',\n",
    "                        'XLC',\n",
    "                        'XLY',\n",
    "                        'XLP',\n",
    "                        'XLE',\n",
    "                        'XLF',\n",
    "                        'XLV',\n",
    "                        'XLI',\n",
    "                        'XLB',\n",
    "                        'XLRE',\n",
    "                        'XLK',\n",
    "                        'XLU',\n",
    "                        '^VIX',\n",
    "                        '^VIX3M',\n",
    "                        'CL=F',\n",
    "                        '^TNX',\n",
    "                        'BTC-USD',\n",
    "                        '^CMC200',\n",
    "                        ]\n",
    "\n",
    "symbol_result_list = ['SPY'\n",
    "                    , 'USO'\n",
    "                     ]\n",
    "\n",
    "input_symbol_01 = \"\"\n",
    "input_symbol_02 = \"\"\n",
    "input_symbol_03 = \"\"\n",
    "output_count = 0\n",
    "\n",
    "days_looking_back = 1\n",
    "\n",
    "# Triple-loop through all of the symbol_eval_list and all of the symbol_result_list\n",
    "# and determine all possible combinations. Write all combos to a list. \n",
    "# Then auto-run machine learning neural networks for each\n",
    "# one of them by looping through the list that was created.\n",
    "# Use the results to determine best candidates for further analysis.\n",
    "# The result is 420 unique combinations to test.\n",
    "\n",
    "# Outer loop through the smaller group of ticker symbols symbol_result_list\n",
    "for x3 in symbol_result_list:\n",
    "  input_symbol_03 = x3\n",
    "  pairings = []\n",
    "  for x1 in symbol_eval_list:\n",
    "    # Then get a ticker symbol from symbol_eval_list\n",
    "    input_symbol_01 = x1\n",
    "    for x2 in symbol_eval_list:\n",
    "      # get another symbol to pair up from ymbol_eval_list \n",
    "      input_symbol_02 = x2\n",
    "      # if the two symbols are not the same, proceed\n",
    "      if input_symbol_01 != input_symbol_02:\n",
    "        pairing_found = 'N'\n",
    "        # loop through the found pairings and check if that pairing already exists (also check the reverse order)\n",
    "        for i in range(len(pairings)):\n",
    "          if (pairing_found == 'N'):\n",
    "            if (pairings[i] == [x1, x2]) | (pairings[i] == [x2, x1]):\n",
    "              pairing_found = 'Y'\n",
    "        # if no pairing has already been writted out, we can process it, so write it now so it won't be processed again and then do all the procesing\n",
    "        if (pairing_found == 'N'):\n",
    "          pairings.append([x1, x2])\n",
    "          print(f\"BEGIN PROCESS\")\n",
    "\n",
    "          # Load ticker1 historical data from Yahoo Finance API\n",
    "          today = date.today()\n",
    "          curr_date = today.strftime(\"%m/%d/%Y\")\n",
    "          df_01 = get_data(input_symbol_01, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_01_min_date = (df_01.iloc[0][\"date\"])\n",
    "\n",
    "          # Load ticker2 historical data from Yahoo Finance API\n",
    "          from datetime import date\n",
    "          today = date.today()\n",
    "          curr_date = today.strftime(\"%m/%d/%Y\")\n",
    "          df_02 = get_data(input_symbol_02, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_02_min_date = (df_02.iloc[0][\"date\"])\n",
    "\n",
    "          # Load ticker3 historical data from Yahoo Finance API\n",
    "          from datetime import date\n",
    "          today = date.today()\n",
    "          curr_date = today.strftime(\"%m/%d/%Y\")\n",
    "          df_03 = get_data(input_symbol_03, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_03_min_date = (df_03.iloc[0][\"date\"])\n",
    "\n",
    "          # Find the first date in each dataframe and get the latest date, that way all dataframes start on the same date when concatinated\n",
    "          latest_date = df_01_min_date\n",
    "          if df_02_min_date > latest_date:\n",
    "            latest_date = df_02_min_date\n",
    "          if df_03_min_date > latest_date:\n",
    "            latest_date = df_03_min_date\n",
    "          print(f\"latest_date: {latest_date}\")\n",
    "          df_01 = df_01[df_01.date >= latest_date]\n",
    "          df_02 = df_02[df_02.date >= latest_date]\n",
    "          df_03 = df_03[df_03.date >= latest_date]\n",
    "          \n",
    "          output_count+=1\n",
    "          print(f\"OUTPUT COUNT: {output_count}\")\n",
    "          # set the column names for this run, based on the ticker symbols\n",
    "          col01 = (f\"{input_symbol_01}_close\")\n",
    "          col02 = (f\"{input_symbol_02}_close\")\n",
    "          col03 = (f\"{input_symbol_03}_close\")\n",
    "\n",
    "          # clean and merge the 3 dataframes, and add some new cols\n",
    "          df = df_01[['date', 'close']].copy()\n",
    "          df = df.rename(columns={'close': col01})\n",
    "          df = df.merge(df_02, on='date')\n",
    "          df = df.rename(columns={'close': col02})\n",
    "          df = df.drop(columns=['open', 'high', 'low', 'adjclose', 'volume', 'ticker'])\n",
    "          df[input_symbol_01+'_percentage'] = \"\"\n",
    "          df[input_symbol_02+'_percentage'] = \"\"\n",
    "          df[input_symbol_01+'_percentage_boolean'] = \"\"\n",
    "          df[input_symbol_02+'_percentage_boolean'] = \"\"\n",
    "#           df['reversion_boolean'] = \"\"\n",
    "          df = df.merge(df_03, on='date')\n",
    "          df = df.rename(columns={'close': col03})\n",
    "          df = df.drop(columns=['open', 'high', 'low', 'adjclose', 'volume', 'ticker'])\n",
    "          df[input_symbol_03+'_future_result'] = \"\"\n",
    "          df[input_symbol_03+'_future_result_boolean'] = \"\"\n",
    "\n",
    "          # loop through the df to populate the new columns\n",
    "          for i in range(len(df)):\n",
    "            if (i < (len(df))):\n",
    "                if (i > (days_looking_back)):\n",
    "                    \n",
    "                    df[input_symbol_01+'_percentage'][i] = ((df[col01][i]) - (df[col01][i-days_looking_back])) / (df[col01][i-days_looking_back])\n",
    "                    if (df[input_symbol_01+'_percentage'][i] != \"\" ):\n",
    "                        if (df[input_symbol_01+'_percentage'][i] > 0 ):\n",
    "                            df[input_symbol_01+'_percentage_boolean'][i] = 1\n",
    "                        else:\n",
    "                            df[input_symbol_01+'_percentage_boolean'][i] = 0\n",
    "                            \n",
    "                    df[input_symbol_02+'_percentage'][i] = ((df[col02][i]) - (df[col02][i-days_looking_back])) / (df[col02][i-days_looking_back])\n",
    "                    if (df[input_symbol_02+'_percentage'][i] != \"\" ):\n",
    "                        if (df[input_symbol_02+'_percentage'][i] > 0 ):\n",
    "                            df[input_symbol_02+'_percentage_boolean'][i] = 1\n",
    "                        else:\n",
    "                            df[input_symbol_02+'_percentage_boolean'][i] = 0\n",
    "            if (i < (len(df)-days_in_future_that_result_is_calculated)):\n",
    "              df[input_symbol_03+'_future_result'][i] = ((df[col03][i+days_in_future_that_result_is_calculated]-df[col03][i])/df[col03][i])\n",
    " \n",
    "\n",
    "                       \n",
    "                        \n",
    "\n",
    "          df = df[df[input_symbol_03+'_future_result'] != \"\"]\n",
    "\n",
    "            \n",
    "#           df = df[df[input_symbol_01+'_percentage'] != \"\"]\n",
    "#           df = df[df[input_symbol_02+'_percentage'] != \"\"]\n",
    "        \n",
    "        \n",
    "\n",
    "          # For the model, pick which cols will be fed into 'X' as inputs\n",
    "          input_column_list_for_X = [\n",
    "              input_symbol_01+\"_close\"\n",
    "            , \n",
    "            input_symbol_02+\"_close\"\n",
    "            # , \n",
    "            # \"percentage\"\n",
    "            # ,\n",
    "            # \"percentage_boolean\"\n",
    "            # ,\n",
    "            # \"reversion_boolean\"\n",
    "            ]\n",
    "          print (f\"input_column_list_for_X: {input_column_list_for_X}\")\n",
    "\n",
    "          # For the model, pick which col will be the 'y' result\n",
    "          output_col_for_y = [\n",
    "              # \"future_result\"\n",
    "              input_symbol_03+\"_future_result_boolean\"\n",
    "              ]\n",
    "          print (f\"output_col_for_y: {output_col_for_y}\")\n",
    "\n",
    "        # make sure numeric\n",
    "          df[input_symbol_03+\"_future_result\"] = pd.to_numeric(df[input_symbol_03+\"_future_result\"])\n",
    "\n",
    "        # set more new cols\n",
    "          for i in range(len(df)):\n",
    "#               if (df[input_symbol_03+'_future_result'][i] != \"\" ):\n",
    "                  if (df[input_symbol_03+'_future_result'][i] > 0):\n",
    "                    df[input_symbol_03+'_future_result_boolean'][i] = 1\n",
    "                  else:\n",
    "                    df[input_symbol_03+'_future_result_boolean'][i] = 0\n",
    "\n",
    "          df[input_symbol_03+\"_future_result_boolean\"] = pd.to_numeric(df[input_symbol_03+\"_future_result_boolean\"])\n",
    "\n",
    "          df = df[df[input_symbol_01+'_percentage'] != \"\"]\n",
    "          df = df[df[input_symbol_02+'_percentage'] != \"\"]\n",
    "        \n",
    "        # make sure numeric\n",
    "          df[input_symbol_01+'_percentage'] = pd.to_numeric(df[input_symbol_01+'_percentage'])\n",
    "          df[input_symbol_01+'_percentage_boolean'] = pd.to_numeric(df[input_symbol_01+'_percentage_boolean'])\n",
    "          df[input_symbol_02+'_percentage'] = pd.to_numeric(df[input_symbol_02+'_percentage'])\n",
    "          df[input_symbol_02+'_percentage_boolean'] = pd.to_numeric(df[input_symbol_02+'_percentage_boolean'])\n",
    "\n",
    "            \n",
    "            \n",
    "          # Remove target 'y' from features data\n",
    "          y = df[output_col_for_y].values\n",
    "\n",
    "          # Pick columns to use for input 'X'\n",
    "          X = df[input_column_list_for_X].values\n",
    "\n",
    "          # Split the preprocessed data into a training and testing dataset\n",
    "          X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "          # Create a StandardScaler instances\n",
    "          scaler = StandardScaler()\n",
    "\n",
    "          # Fit the StandardScaler\n",
    "          X_scaler = scaler.fit(X_train)\n",
    "\n",
    "          # Scale the data\n",
    "          if scale_data == \"N\":\n",
    "            import numpy as np\n",
    "            X_train = np.asarray(X_train).astype(np.float64)\n",
    "            X_train_scaled = X_train\n",
    "            X_test = np.asarray(X_test).astype(np.float64)\n",
    "            X_test_scaled = X_test\n",
    "          else:\n",
    "            X_train_scaled = X_scaler.transform(X_train)\n",
    "            X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "          # Compile, Train and Evaluate the Model\n",
    "\n",
    "          number_input_features = len(X_train[0])\n",
    "\n",
    "          nn = tf.keras.models.Sequential()\n",
    "\n",
    "          # First hidden layer\n",
    "          hidden_nodes_layer1 = num_nodes\n",
    "          nn.add(\n",
    "              tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_type)\n",
    "          )\n",
    "          if num_layers >= 2:\n",
    "            # second hidden layer\n",
    "            hidden_nodes_layer2 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=activation_type))\n",
    "          if num_layers >= 3:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer3 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=activation_type))\n",
    "          if num_layers >= 4:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer4 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=activation_type))\n",
    "          if num_layers >= 5:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer5 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=activation_type))\n",
    "          if num_layers >= 6:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer6 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=activation_type))\n",
    "          if num_layers >= 7:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer7 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer7, activation=activation_type))\n",
    "          if num_layers >= 8:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer8 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer8, activation=activation_type))\n",
    "          if num_layers >= 9:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer9 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer9, activation=activation_type))\n",
    "          if num_layers >= 10:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer10 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer10, activation=activation_type))\n",
    "\n",
    "          # Output layer\n",
    "          nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "          # Check the structure of the model\n",
    "          nn.summary()\n",
    "\n",
    "          # Compile the model\n",
    "          nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "          # Train the model\n",
    "          fit_model = nn.fit(X_train_scaled,y_train,epochs=num_epochs)\n",
    "\n",
    "          # Evaluate the model using the test data\n",
    "          model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "\n",
    "          # Need to document well the RESULTS from EACH run - this output will be just one of hundreds of loops in the output\n",
    "          print(f\"RESULTS\")\n",
    "          print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "          print(f\"Symbol 01: {input_symbol_01}\")\n",
    "          print(f\"Symbol 02: {input_symbol_02}\")\n",
    "          print(f\"Symbol 03: {input_symbol_03}\")\n",
    "          print(f\"Scale Data = {scale_data}\")\n",
    "          print(f\"activation_type = {activation_type}\")\n",
    "          print(f\"num_epochs = {num_epochs}\")\n",
    "          print(f\"num_layers = {num_layers}\")\n",
    "          print(f\"Layer 1 Nodes = {hidden_nodes_layer1}\")\n",
    "          if num_layers >= 2:\n",
    "            print(f\"Layer 2 Nodes = {hidden_nodes_layer2}\")\n",
    "          if num_layers >= 3:\n",
    "            print(f\"Layer 3 Nodes: {hidden_nodes_layer3}\")\n",
    "          if num_layers >= 4:\n",
    "            print(f\"Layer 4 Nodes = {hidden_nodes_layer4}\")\n",
    "          if num_layers >= 5:\n",
    "            print(f\"Layer 5 Nodes = {hidden_nodes_layer5}\")\n",
    "          if num_layers >= 6:\n",
    "            print(f\"Layer 6 Nodes = {hidden_nodes_layer6}\")\n",
    "          if num_layers >= 7:\n",
    "            print(f\"Layer 7 Nodes = {hidden_nodes_layer7}\")\n",
    "          if num_layers >= 8:\n",
    "            print(f\"Layer 8 Nodes = {hidden_nodes_layer8}\")\n",
    "          if num_layers >= 9:\n",
    "            print(f\"Layer 9 Nodes = {hidden_nodes_layer9}\")\n",
    "          if num_layers >= 10:\n",
    "            print(f\"Layer 10 Nodes = {hidden_nodes_layer10}\")\n",
    "          \n",
    "          print(\"\")\n",
    "          print(\"\")\n",
    "          print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>^GSPC_close</th>\n",
       "      <th>^DJI_close</th>\n",
       "      <th>^GSPC_percentage</th>\n",
       "      <th>^DJI_percentage</th>\n",
       "      <th>^GSPC_percentage_boolean</th>\n",
       "      <th>^DJI_percentage_boolean</th>\n",
       "      <th>SPY_close</th>\n",
       "      <th>SPY_future_result</th>\n",
       "      <th>SPY_future_result_boolean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>11122.650391</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.011340</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>-0.046094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>11253.259766</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.750000</td>\n",
       "      <td>-0.062160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>11522.559570</td>\n",
       "      <td>0.027090</td>\n",
       "      <td>0.023931</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145.750000</td>\n",
       "      <td>-0.106775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>1457.599976</td>\n",
       "      <td>11572.200195</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>146.250000</td>\n",
       "      <td>-0.112179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01-11</td>\n",
       "      <td>1438.560059</td>\n",
       "      <td>11511.080078</td>\n",
       "      <td>-0.013063</td>\n",
       "      <td>-0.005282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144.500000</td>\n",
       "      <td>-0.085640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>3757.989990</td>\n",
       "      <td>30076.679688</td>\n",
       "      <td>-0.008428</td>\n",
       "      <td>-0.003548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>374.220001</td>\n",
       "      <td>0.155016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>3693.229980</td>\n",
       "      <td>29590.410156</td>\n",
       "      <td>-0.017233</td>\n",
       "      <td>-0.016168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>367.950012</td>\n",
       "      <td>0.157440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>3655.040039</td>\n",
       "      <td>29260.810547</td>\n",
       "      <td>-0.010341</td>\n",
       "      <td>-0.011139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364.309998</td>\n",
       "      <td>0.169471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>3647.290039</td>\n",
       "      <td>29134.990234</td>\n",
       "      <td>-0.002120</td>\n",
       "      <td>-0.004300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>363.380005</td>\n",
       "      <td>0.179261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>3719.040039</td>\n",
       "      <td>29683.740234</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.018835</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>370.529999</td>\n",
       "      <td>0.153699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5720 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  ^GSPC_close    ^DJI_close  ^GSPC_percentage  ^DJI_percentage  \\\n",
       "2    2000-01-05  1402.109985  11122.650391          0.001922         0.011340   \n",
       "3    2000-01-06  1403.449951  11253.259766          0.000956         0.011743   \n",
       "4    2000-01-07  1441.469971  11522.559570          0.027090         0.023931   \n",
       "5    2000-01-10  1457.599976  11572.200195          0.011190         0.004308   \n",
       "6    2000-01-11  1438.560059  11511.080078         -0.013063        -0.005282   \n",
       "...         ...          ...           ...               ...              ...   \n",
       "5717 2022-09-22  3757.989990  30076.679688         -0.008428        -0.003548   \n",
       "5718 2022-09-23  3693.229980  29590.410156         -0.017233        -0.016168   \n",
       "5719 2022-09-26  3655.040039  29260.810547         -0.010341        -0.011139   \n",
       "5720 2022-09-27  3647.290039  29134.990234         -0.002120        -0.004300   \n",
       "5721 2022-09-28  3719.040039  29683.740234          0.019672         0.018835   \n",
       "\n",
       "      ^GSPC_percentage_boolean  ^DJI_percentage_boolean   SPY_close  \\\n",
       "2                            1                        1  140.000000   \n",
       "3                            1                        1  137.750000   \n",
       "4                            1                        1  145.750000   \n",
       "5                            1                        1  146.250000   \n",
       "6                            0                        0  144.500000   \n",
       "...                        ...                      ...         ...   \n",
       "5717                         0                        0  374.220001   \n",
       "5718                         0                        0  367.950012   \n",
       "5719                         0                        0  364.309998   \n",
       "5720                         0                        0  363.380005   \n",
       "5721                         1                        1  370.529999   \n",
       "\n",
       "      SPY_future_result  SPY_future_result_boolean  \n",
       "2             -0.046094                          0  \n",
       "3             -0.062160                          0  \n",
       "4             -0.106775                          0  \n",
       "5             -0.112179                          0  \n",
       "6             -0.085640                          0  \n",
       "...                 ...                        ...  \n",
       "5717           0.155016                          1  \n",
       "5718           0.157440                          1  \n",
       "5719           0.169471                          1  \n",
       "5720           0.179261                          1  \n",
       "5721           0.153699                          1  \n",
       "\n",
       "[5720 rows x 10 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5724)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
