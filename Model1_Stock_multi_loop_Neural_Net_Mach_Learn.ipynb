{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fh3PmurW-WFG"
   },
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRVDUu5nMiQk",
    "outputId": "f8214e1a-c902-4d4c-bb49-2e93fe1d1548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yahoo_fin in c:\\users\\mlech\\anaconda3\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: requests-html in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (0.10.0)\n",
      "Requirement already satisfied: feedparser in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (6.0.10)\n",
      "Requirement already satisfied: requests in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (2.28.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (1.4.4)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from feedparser->yahoo_fin) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (1.23.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (2022.12.7)\n",
      "Requirement already satisfied: pyquery in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (2.0.0)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.1.3)\n",
      "Requirement already satisfied: parse in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.19.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (0.0.1)\n",
      "Requirement already satisfied: w3lib in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.21.0)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.0.2)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.11.3)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (8.2.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.64.1)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (10.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->yahoo_fin) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from bs4->requests-html->yahoo_fin) (4.11.1)\n",
      "Requirement already satisfied: importlib-resources>=5.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from fake-useragent->requests-html->yahoo_fin) (5.12.0)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyquery->requests-html->yahoo_fin) (4.9.1)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyquery->requests-html->yahoo_fin) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests-html->yahoo_fin) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->requests-html->yahoo_fin) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yahoo_fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6Mb-Apq5M02C"
   },
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AROMFS4N-jot",
    "outputId": "70855e4a-02ed-43bf-993c-8f84c90fe451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days in future that result is calculated: 252\n",
      "reversion_low_value: 12\n",
      "reversion_high_value: 20\n",
      "optimization_max_epochs: 5\n",
      "optimization_max_hidden_layers: 5\n",
      "BEGIN PROCESS\n",
      "latest_date: 2000-01-03 00:00:00\n",
      "OUTPUT COUNT: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_7680\\3677634320.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.percentage[i] = (df[col02][i]/df[col01][i])\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_7680\\3677634320.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.reversion_boolean[i] = 0\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_7680\\3677634320.py:171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.future_result[i] = ((df[col03][i+days_in_future_that_result_is_calculated]-df[col03][i])/df[col03][i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_column_list_for_X: ['^GSPC_close', '^DJI_close']\n",
      "output_col_for_y: ['future_result_boolean']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_7680\\3677634320.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.percentage_boolean[i] = 1\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_7680\\3677634320.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.future_result_boolean[i] = 0\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_7680\\3677634320.py:209: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.future_result_boolean[i] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51 (204.00 Byte)\n",
      "Trainable params: 51 (204.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "135/135 [==============================] - 0s 746us/step - loss: 0.6374 - accuracy: 0.6893\n",
      "Epoch 2/5\n",
      "135/135 [==============================] - 0s 702us/step - loss: 0.5835 - accuracy: 0.7280\n",
      "Epoch 3/5\n",
      "135/135 [==============================] - 0s 697us/step - loss: 0.5597 - accuracy: 0.7280\n",
      "Epoch 4/5\n",
      "135/135 [==============================] - 0s 798us/step - loss: 0.5428 - accuracy: 0.7329\n",
      "Epoch 5/5\n",
      "135/135 [==============================] - 0s 720us/step - loss: 0.5317 - accuracy: 0.7522\n",
      "45/45 - 0s - loss: 0.5470 - accuracy: 0.7379 - 83ms/epoch - 2ms/step\n",
      "RESULTS\n",
      "Loss: 0.546951174736023, Accuracy: 0.7379454970359802\n",
      "Symbol 01: ^GSPC\n",
      "Symbol 02: ^DJI\n",
      "Symbol 03: SPY\n",
      "Scale Data = Y\n",
      "activation_type = relu\n",
      "num_epochs = 5\n",
      "num_layers = 2\n",
      "Layer 1 Nodes = 5\n",
      "Layer 2 Nodes = 5\n",
      "\n",
      "\n",
      "\n",
      "BEGIN PROCESS\n",
      "latest_date: 2000-01-03 00:00:00\n",
      "OUTPUT COUNT: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_7680\\3677634320.py:165: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.percentage[i] = (df[col02][i]/df[col01][i])\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_7680\\3677634320.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.reversion_boolean[i] = 0\n",
      "C:\\Users\\mlech\\AppData\\Local\\Temp\\ipykernel_7680\\3677634320.py:171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.future_result[i] = ((df[col03][i+days_in_future_that_result_is_calculated]-df[col03][i])/df[col03][i])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7680\\3677634320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    163\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m               \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpercentage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol02\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol01\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol01\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mreversion_low_value\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol01\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mreversion_high_value\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreversion_boolean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy, inplace)\u001b[0m\n\u001b[0;32m   1277\u001b[0m                 \u001b[1;31m# to ensure column still in dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m                 \u001b[1;31m# otherwise, either self or ref has swapped in new arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1279\u001b[1;33m                 \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1280\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1281\u001b[0m                 \u001b[1;31m# GH#33675 we have swapped in a new array, so parent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[1;34m(self, item, value, inplace)\u001b[0m\n\u001b[0;32m   3954\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3956\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3957\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3958\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36miset\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Accessing public blknos ensures the public versions are initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mblknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mblklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[0munfit_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# ***************************\n",
    "# ***                     ***\n",
    "# ***    SET VARIABLES    ***\n",
    "# ***                     ***\n",
    "# ***************************\n",
    "\n",
    "days_in_future_that_result_is_calculated = 252\n",
    "print(f\"Days in future that result is calculated: {days_in_future_that_result_is_calculated}\")\n",
    "\n",
    "reversion_low_value = 12\n",
    "print(f\"reversion_low_value: {reversion_low_value}\")\n",
    "\n",
    "reversion_high_value = 20\n",
    "print(f\"reversion_high_value: {reversion_high_value}\")\n",
    "\n",
    "optimization_max_epochs = 5\n",
    "print(f\"optimization_max_epochs: {optimization_max_epochs}\")\n",
    "\n",
    "# Max 10:\n",
    "optimization_max_hidden_layers = 5\n",
    "print(f\"optimization_max_hidden_layers: {optimization_max_hidden_layers}\")\n",
    "\n",
    "optimization_max_nodes = 5\n",
    "\n",
    "\n",
    "activation_type = 'relu'\n",
    "\n",
    "# Max 10:\n",
    "num_layers = 2\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "num_nodes = 5\n",
    "\n",
    "\n",
    "# SCALE THE DATA? \"Y\" or \"N\":\n",
    "scale_data = \"Y\"\n",
    "\n",
    "\n",
    "# TICKER SYMBOLS TO PROCESS:\n",
    "\n",
    "# 21 symbols to pair up, plus 2 result tickers to test output,\n",
    "# so 210 unique pairs * 2 outputs = 420 combinations are \n",
    "# looped through and be tested\n",
    "\n",
    "symbol_eval_list = [\n",
    "                        '^GSPC',\n",
    "                        '^DJI',\n",
    "                        '^IXIC',\n",
    "                        '^RUT',\n",
    "                        'XLC',\n",
    "                        'XLY',\n",
    "                        'XLP',\n",
    "                        'XLE',\n",
    "                        'XLF',\n",
    "                        'XLV',\n",
    "                        'XLI',\n",
    "                        'XLB',\n",
    "                        'XLRE',\n",
    "                        'XLK',\n",
    "                        'XLU',\n",
    "                        '^VIX',\n",
    "                        '^VIX3M',\n",
    "                        'CL=F',\n",
    "                        '^TNX',\n",
    "                        'BTC-USD',\n",
    "                        '^CMC200',\n",
    "                        ]\n",
    "\n",
    "symbol_result_list = ['SPY'\n",
    "                    , 'USO'\n",
    "                     ]\n",
    "\n",
    "input_symbol_01 = \"\"\n",
    "input_symbol_02 = \"\"\n",
    "input_symbol_03 = \"\"\n",
    "output_count = 0\n",
    "\n",
    "# Triple-loop through all of the symbol_eval_list and all of the symbol_result_list\n",
    "# and determine all possible combinations. Write all combos to a list. \n",
    "# Then auto-run machine learning neural networks for each\n",
    "# one of them by looping through the list that was created.\n",
    "# Use the results to determine best candidates for further analysis.\n",
    "# The result is 420 unique combinations to test.\n",
    "\n",
    "# Outer loop through the smaller group of ticker symbols symbol_result_list\n",
    "for x3 in symbol_result_list:\n",
    "  input_symbol_03 = x3\n",
    "  pairings = []\n",
    "  for x1 in symbol_eval_list:\n",
    "    # Then get a ticker symbol from symbol_eval_list\n",
    "    input_symbol_01 = x1\n",
    "    for x2 in symbol_eval_list:\n",
    "      # get another symbol to pair up from ymbol_eval_list \n",
    "      input_symbol_02 = x2\n",
    "      # if the two symbols are not the same, proceed\n",
    "      if input_symbol_01 != input_symbol_02:\n",
    "        pairing_found = 'N'\n",
    "        # loop through the found pairings and check if that pairing already exists (also check the reverse order)\n",
    "        for i in range(len(pairings)):\n",
    "          if (pairing_found == 'N'):\n",
    "            if (pairings[i] == [x1, x2]) | (pairings[i] == [x2, x1]):\n",
    "              pairing_found = 'Y'\n",
    "        # if no pairing has already been writted out, we can process it, so write it now so it won't be processed again and then do all the procesing\n",
    "        if (pairing_found == 'N'):\n",
    "          pairings.append([x1, x2])\n",
    "          print(f\"BEGIN PROCESS\")\n",
    "\n",
    "          # Load ticker1 historical data from Yahoo Finance API\n",
    "          today = date.today()\n",
    "          curr_date = today.strftime(\"%m/%d/%Y\")\n",
    "          df_01 = get_data(input_symbol_01, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_01_min_date = (df_01.iloc[0][\"date\"])\n",
    "\n",
    "          # Load ticker2 historical data from Yahoo Finance API\n",
    "          from datetime import date\n",
    "          today = date.today()\n",
    "          curr_date = today.strftime(\"%m/%d/%Y\")\n",
    "          df_02 = get_data(input_symbol_02, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_02_min_date = (df_02.iloc[0][\"date\"])\n",
    "\n",
    "          # Load ticker3 historical data from Yahoo Finance API\n",
    "          from datetime import date\n",
    "          today = date.today()\n",
    "          curr_date = today.strftime(\"%m/%d/%Y\")\n",
    "          df_03 = get_data(input_symbol_03, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_03_min_date = (df_03.iloc[0][\"date\"])\n",
    "\n",
    "          # Find the first date in each dataframe and get the latest date, that way all dataframes start on the same date when concatinated\n",
    "          latest_date = df_01_min_date\n",
    "          if df_02_min_date > latest_date:\n",
    "            latest_date = df_02_min_date\n",
    "          if df_03_min_date > latest_date:\n",
    "            latest_date = df_03_min_date\n",
    "          print(f\"latest_date: {latest_date}\")\n",
    "          df_01 = df_01[df_01.date >= latest_date]\n",
    "          df_02 = df_02[df_02.date >= latest_date]\n",
    "          df_03 = df_03[df_03.date >= latest_date]\n",
    "          \n",
    "          output_count+=1\n",
    "          print(f\"OUTPUT COUNT: {output_count}\")\n",
    "          # set the column names for this run, based on the ticker symbols\n",
    "          col01 = (f\"{input_symbol_01}_close\")\n",
    "          col02 = (f\"{input_symbol_02}_close\")\n",
    "          col03 = (f\"{input_symbol_03}_close\")\n",
    "\n",
    "          # clean and merge the 3 dataframes, and add some new cols\n",
    "          df = df_01[['date', 'close']].copy()\n",
    "          df = df.rename(columns={'close': col01})\n",
    "          df = df.merge(df_02, on='date')\n",
    "          df = df.rename(columns={'close': col02})\n",
    "          df = df.drop(columns=['open', 'high', 'low', 'adjclose', 'volume', 'ticker'])\n",
    "          df['percentage'] = \"\"\n",
    "          df['percentage_boolean'] = \"\"\n",
    "          df['reversion_boolean'] = \"\"\n",
    "          df = df.merge(df_03, on='date')\n",
    "          df = df.rename(columns={'close': col03})\n",
    "          df = df.drop(columns=['open', 'high', 'low', 'adjclose', 'volume', 'ticker'])\n",
    "          df['future_result'] = \"\"\n",
    "          df['future_result_boolean'] = \"\"\n",
    "\n",
    "          # loop through the df to populate the new columns\n",
    "          for i in range(len(df)):\n",
    "            if (i < (len(df))):\n",
    "              df.percentage[i] = (df[col02][i]/df[col01][i])\n",
    "              if ( (df[col01][i] > reversion_low_value) & (df[col01][i] < reversion_high_value) ):\n",
    "                df.reversion_boolean[i] = 1\n",
    "              else:\n",
    "                df.reversion_boolean[i] = 0\n",
    "            if (i < (len(df)-days_in_future_that_result_is_calculated)):\n",
    "              df.future_result[i] = ((df[col03][i+days_in_future_that_result_is_calculated]-df[col03][i])/df[col03][i])\n",
    "\n",
    "          df = df[df['future_result'] != \"\"]\n",
    "\n",
    "\n",
    "          # For the model, pick which cols will be fed into 'X' as inputs\n",
    "          input_column_list_for_X = [\n",
    "              input_symbol_01+\"_close\"\n",
    "            , \n",
    "            input_symbol_02+\"_close\"\n",
    "            # , \n",
    "            # \"percentage\"\n",
    "            # ,\n",
    "            # \"percentage_boolean\"\n",
    "            # ,\n",
    "            # \"reversion_boolean\"\n",
    "            ]\n",
    "          print (f\"input_column_list_for_X: {input_column_list_for_X}\")\n",
    "\n",
    "          # For the model, pick which col will be the 'y' result\n",
    "          output_col_for_y = [\n",
    "              # \"future_result\"\n",
    "              \"future_result_boolean\"\n",
    "              ]\n",
    "          print (f\"output_col_for_y: {output_col_for_y}\")\n",
    "\n",
    "          # make sure numeric\n",
    "          df[\"percentage\"] = pd.to_numeric(df[\"percentage\"])\n",
    "          df[\"reversion_boolean\"] = pd.to_numeric(df[\"reversion_boolean\"])\n",
    "          df[\"future_result\"] = pd.to_numeric(df[\"future_result\"])\n",
    "\n",
    "          # set more new cols\n",
    "          for i in range(len(df)):\n",
    "              if (df['percentage'][i] > 1):\n",
    "                df.percentage_boolean[i] = 1\n",
    "              else:\n",
    "                df.percentage_boolean[i] = 0\n",
    "              if (df['future_result'][i] > 0):\n",
    "                df.future_result_boolean[i] = 1\n",
    "              else:\n",
    "                df.future_result_boolean[i] = 0\n",
    "\n",
    "          df[\"future_result_boolean\"] = pd.to_numeric(df[\"future_result_boolean\"])\n",
    "          df[\"percentage_boolean\"] = pd.to_numeric(df[\"percentage_boolean\"])\n",
    "\n",
    "          # Remove target 'y' from features data\n",
    "          y = df[output_col_for_y].values\n",
    "\n",
    "          # Pick columns to use for input 'X'\n",
    "          X = df[input_column_list_for_X].values\n",
    "\n",
    "          # Split the preprocessed data into a training and testing dataset\n",
    "          X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "          # Create a StandardScaler instances\n",
    "          scaler = StandardScaler()\n",
    "\n",
    "          # Fit the StandardScaler\n",
    "          X_scaler = scaler.fit(X_train)\n",
    "\n",
    "          # Scale the data\n",
    "          if scale_data == \"N\":\n",
    "            import numpy as np\n",
    "            X_train = np.asarray(X_train).astype(np.float64)\n",
    "            X_train_scaled = X_train\n",
    "            X_test = np.asarray(X_test).astype(np.float64)\n",
    "            X_test_scaled = X_test\n",
    "          else:\n",
    "            X_train_scaled = X_scaler.transform(X_train)\n",
    "            X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "          # Compile, Train and Evaluate the Model\n",
    "\n",
    "          number_input_features = len(X_train[0])\n",
    "\n",
    "          nn = tf.keras.models.Sequential()\n",
    "\n",
    "          # First hidden layer\n",
    "          hidden_nodes_layer1 = num_nodes\n",
    "          nn.add(\n",
    "              tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_type)\n",
    "          )\n",
    "          if num_layers >= 2:\n",
    "            # second hidden layer\n",
    "            hidden_nodes_layer2 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=activation_type))\n",
    "          if num_layers >= 3:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer3 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=activation_type))\n",
    "          if num_layers >= 4:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer4 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=activation_type))\n",
    "          if num_layers >= 5:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer5 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=activation_type))\n",
    "          if num_layers >= 6:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer6 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=activation_type))\n",
    "          if num_layers >= 7:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer7 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer7, activation=activation_type))\n",
    "          if num_layers >= 8:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer8 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer8, activation=activation_type))\n",
    "          if num_layers >= 9:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer9 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer9, activation=activation_type))\n",
    "          if num_layers >= 10:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer10 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer10, activation=activation_type))\n",
    "\n",
    "          # Output layer\n",
    "          nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "          # Check the structure of the model\n",
    "          nn.summary()\n",
    "\n",
    "          # Compile the model\n",
    "          nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "          # Train the model\n",
    "          fit_model = nn.fit(X_train_scaled,y_train,epochs=num_epochs)\n",
    "\n",
    "          # Evaluate the model using the test data\n",
    "          model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "\n",
    "          # Need to document well the RESULTS from EACH run - this output will be just one of hundreds of loops in the output\n",
    "          print(f\"RESULTS\")\n",
    "          print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "          print(f\"Symbol 01: {input_symbol_01}\")\n",
    "          print(f\"Symbol 02: {input_symbol_02}\")\n",
    "          print(f\"Symbol 03: {input_symbol_03}\")\n",
    "          print(f\"Scale Data = {scale_data}\")\n",
    "          print(f\"activation_type = {activation_type}\")\n",
    "          print(f\"num_epochs = {num_epochs}\")\n",
    "          print(f\"num_layers = {num_layers}\")\n",
    "          print(f\"Layer 1 Nodes = {hidden_nodes_layer1}\")\n",
    "          if num_layers >= 2:\n",
    "            print(f\"Layer 2 Nodes = {hidden_nodes_layer2}\")\n",
    "          if num_layers >= 3:\n",
    "            print(f\"Layer 3 Nodes: {hidden_nodes_layer3}\")\n",
    "          if num_layers >= 4:\n",
    "            print(f\"Layer 4 Nodes = {hidden_nodes_layer4}\")\n",
    "          if num_layers >= 5:\n",
    "            print(f\"Layer 5 Nodes = {hidden_nodes_layer5}\")\n",
    "          if num_layers >= 6:\n",
    "            print(f\"Layer 6 Nodes = {hidden_nodes_layer6}\")\n",
    "          if num_layers >= 7:\n",
    "            print(f\"Layer 7 Nodes = {hidden_nodes_layer7}\")\n",
    "          if num_layers >= 8:\n",
    "            print(f\"Layer 8 Nodes = {hidden_nodes_layer8}\")\n",
    "          if num_layers >= 9:\n",
    "            print(f\"Layer 9 Nodes = {hidden_nodes_layer9}\")\n",
    "          if num_layers >= 10:\n",
    "            print(f\"Layer 10 Nodes = {hidden_nodes_layer10}\")\n",
    "          \n",
    "          print(\"\")\n",
    "          print(\"\")\n",
    "          print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>^GSPC_close</th>\n",
       "      <th>^IXIC_close</th>\n",
       "      <th>percentage</th>\n",
       "      <th>percentage_boolean</th>\n",
       "      <th>reversion_boolean</th>\n",
       "      <th>SPY_close</th>\n",
       "      <th>future_result</th>\n",
       "      <th>future_result_boolean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>4131.149902</td>\n",
       "      <td>2.838849</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>145.437500</td>\n",
       "      <td>-0.11431</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>3901.689941</td>\n",
       "      <td>2.788076</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>139.750000</td>\n",
       "      <td>-0.033989</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>3877.540039</td>\n",
       "      <td>2.765503</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>-0.046094</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>3727.129883</td>\n",
       "      <td>2.655691</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>137.750000</td>\n",
       "      <td>-0.06216</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>3882.620117</td>\n",
       "      <td>2.693514</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>145.750000</td>\n",
       "      <td>-0.106775</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2003-01-07</td>\n",
       "      <td>922.929993</td>\n",
       "      <td>1431.569946</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>92.730003</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>2003-01-08</td>\n",
       "      <td>909.929993</td>\n",
       "      <td>1401.069946</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>91.389999</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>2003-01-09</td>\n",
       "      <td>927.570007</td>\n",
       "      <td>1438.459961</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>92.809998</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>2003-01-10</td>\n",
       "      <td>927.570007</td>\n",
       "      <td>1447.719971</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>93.059998</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2003-01-13</td>\n",
       "      <td>926.260010</td>\n",
       "      <td>1446.040039</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>93.029999</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  ^GSPC_close  ^IXIC_close percentage percentage_boolean  \\\n",
       "0   2000-01-03  1455.219971  4131.149902   2.838849                      \n",
       "1   2000-01-04  1399.420044  3901.689941   2.788076                      \n",
       "2   2000-01-05  1402.109985  3877.540039   2.765503                      \n",
       "3   2000-01-06  1403.449951  3727.129883   2.655691                      \n",
       "4   2000-01-07  1441.469971  3882.620117   2.693514                      \n",
       "..         ...          ...          ...        ...                ...   \n",
       "755 2003-01-07   922.929993  1431.569946                                 \n",
       "756 2003-01-08   909.929993  1401.069946                                 \n",
       "757 2003-01-09   927.570007  1438.459961                                 \n",
       "758 2003-01-10   927.570007  1447.719971                                 \n",
       "759 2003-01-13   926.260010  1446.040039                                 \n",
       "\n",
       "    reversion_boolean   SPY_close future_result future_result_boolean  \n",
       "0                   0  145.437500      -0.11431                        \n",
       "1                   0  139.750000     -0.033989                        \n",
       "2                   0  140.000000     -0.046094                        \n",
       "3                   0  137.750000      -0.06216                        \n",
       "4                   0  145.750000     -0.106775                        \n",
       "..                ...         ...           ...                   ...  \n",
       "755                     92.730003                                      \n",
       "756                     91.389999                                      \n",
       "757                     92.809998                                      \n",
       "758                     93.059998                                      \n",
       "759                     93.029999                                      \n",
       "\n",
       "[760 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
