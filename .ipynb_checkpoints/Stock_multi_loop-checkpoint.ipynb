{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "fh3PmurW-WFG"
   },
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRVDUu5nMiQk",
    "outputId": "f8214e1a-c902-4d4c-bb49-2e93fe1d1548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yahoo_fin in c:\\users\\mlech\\anaconda3\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: requests-html in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (0.10.0)\n",
      "Requirement already satisfied: feedparser in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (6.0.10)\n",
      "Requirement already satisfied: requests in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (2.28.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (1.4.4)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from feedparser->yahoo_fin) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (1.23.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (2022.12.7)\n",
      "Requirement already satisfied: pyquery in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (2.0.0)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.1.3)\n",
      "Requirement already satisfied: parse in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.19.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (0.0.1)\n",
      "Requirement already satisfied: w3lib in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.21.0)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.0.2)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.11.3)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (8.2.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.64.1)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (10.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->yahoo_fin) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from bs4->requests-html->yahoo_fin) (4.11.1)\n",
      "Requirement already satisfied: importlib-resources>=5.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from fake-useragent->requests-html->yahoo_fin) (5.12.0)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyquery->requests-html->yahoo_fin) (4.9.1)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyquery->requests-html->yahoo_fin) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests-html->yahoo_fin) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->requests-html->yahoo_fin) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yahoo_fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "6Mb-Apq5M02C"
   },
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AROMFS4N-jot",
    "outputId": "70855e4a-02ed-43bf-993c-8f84c90fe451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days looking back for inputs that it is testing against: 1\n",
      "Days in the future that the result is calculated for:    5\n",
      "optimization_max_epochs: 5\n",
      "optimization_max_hidden_layers: 5\n",
      "BEGIN PROCESS\n",
      "latest_date: 2000-01-03 00:00:00\n",
      "OUTPUT COUNT: 1\n",
      "input_column_list_for_X: ['^GSPC_percentage_boolean', '^DJI_percentage_boolean']\n",
      "output_col_for_y: ['SPY_future_result_boolean']\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_229 (Dense)           (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51 (204.00 Byte)\n",
      "Trainable params: 51 (204.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 800us/step - loss: 0.6901 - accuracy: 0.5588\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 807us/step - loss: 0.6889 - accuracy: 0.5614\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 810us/step - loss: 0.6880 - accuracy: 0.5614\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 802us/step - loss: 0.6874 - accuracy: 0.5614\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 805us/step - loss: 0.6870 - accuracy: 0.5614\n",
      "47/47 - 0s - loss: 0.6833 - accuracy: 0.5845 - 149ms/epoch - 3ms/step\n",
      "RESULTS\n",
      "Loss: 0.6833147406578064, Accuracy: 0.5844504237174988\n",
      "Symbol 01: ^GSPC\n",
      "Symbol 02: ^DJI\n",
      "Symbol 03: SPY\n",
      "Scale Data = N\n",
      "activation_type = relu\n",
      "num_epochs = 5\n",
      "num_layers = 2\n",
      "Layer 1 Nodes = 5\n",
      "Layer 2 Nodes = 5\n",
      "\n",
      "\n",
      "\n",
      "BEGIN PROCESS\n",
      "latest_date: 2000-01-03 00:00:00\n",
      "OUTPUT COUNT: 2\n",
      "input_column_list_for_X: ['^GSPC_percentage_boolean', '^IXIC_percentage_boolean']\n",
      "output_col_for_y: ['SPY_future_result_boolean']\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_232 (Dense)           (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_234 (Dense)           (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51 (204.00 Byte)\n",
      "Trainable params: 51 (204.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 792us/step - loss: 0.7041 - accuracy: 0.5201\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 830us/step - loss: 0.6861 - accuracy: 0.5614\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 818us/step - loss: 0.6856 - accuracy: 0.5614\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 807us/step - loss: 0.6855 - accuracy: 0.5614\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 805us/step - loss: 0.6857 - accuracy: 0.5614\n",
      "47/47 - 0s - loss: 0.6799 - accuracy: 0.5845 - 150ms/epoch - 3ms/step\n",
      "RESULTS\n",
      "Loss: 0.6798749566078186, Accuracy: 0.5844504237174988\n",
      "Symbol 01: ^GSPC\n",
      "Symbol 02: ^IXIC\n",
      "Symbol 03: SPY\n",
      "Scale Data = N\n",
      "activation_type = relu\n",
      "num_epochs = 5\n",
      "num_layers = 2\n",
      "Layer 1 Nodes = 5\n",
      "Layer 2 Nodes = 5\n",
      "\n",
      "\n",
      "\n",
      "BEGIN PROCESS\n",
      "latest_date: 2000-01-03 00:00:00\n",
      "OUTPUT COUNT: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20876\\930125827.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdays_looking_back\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m                     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_symbol_01\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_percentage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol01\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol01\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdays_looking_back\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol01\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdays_looking_back\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_symbol_01\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_percentage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_symbol_01\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_percentage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy, inplace)\u001b[0m\n\u001b[0;32m   1277\u001b[0m                 \u001b[1;31m# to ensure column still in dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m                 \u001b[1;31m# otherwise, either self or ref has swapped in new arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1279\u001b[1;33m                 \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1280\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1281\u001b[0m                 \u001b[1;31m# GH#33675 we have swapped in a new array, so parent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[1;34m(self, item, value, inplace)\u001b[0m\n\u001b[0;32m   3954\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3956\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3957\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3958\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36miset\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Accessing public blknos ensures the public versions are initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mblknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mblklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[0munfit_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# ***************************\n",
    "# ***                     ***\n",
    "# ***    SET VARIABLES    ***\n",
    "# ***                     ***\n",
    "# ***************************\n",
    "\n",
    "days_looking_back = 1\n",
    "print(f\"Days looking back for inputs that it is testing against: {days_looking_back}\")\n",
    "\n",
    "days_in_future_that_result_is_calculated = 5\n",
    "print(f\"Days in the future that the result is calculated for:    {days_in_future_that_result_is_calculated}\")\n",
    "\n",
    "# reversion_low_value = 12\n",
    "# print(f\"reversion_low_value: {reversion_low_value}\")\n",
    "\n",
    "# reversion_high_value = 20\n",
    "# print(f\"reversion_high_value: {reversion_high_value}\")\n",
    "\n",
    "optimization_max_epochs = 5\n",
    "print(f\"optimization_max_epochs: {optimization_max_epochs}\")\n",
    "\n",
    "# Max 10:\n",
    "optimization_max_hidden_layers = 5\n",
    "print(f\"optimization_max_hidden_layers: {optimization_max_hidden_layers}\")\n",
    "\n",
    "optimization_max_nodes = 5\n",
    "\n",
    "\n",
    "activation_type = 'relu'\n",
    "\n",
    "# Max 10:\n",
    "num_layers = 2\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "num_nodes = 5\n",
    "\n",
    "\n",
    "# SCALE THE DATA? \"Y\" or \"N\":\n",
    "scale_data = \"N\"\n",
    "\n",
    "\n",
    "# TICKER SYMBOLS TO PROCESS:\n",
    "\n",
    "# 21 symbols to pair up, plus 2 result tickers to test output,\n",
    "# so 210 unique pairs * 2 outputs = 420 combinations are \n",
    "# looped through and be tested\n",
    "\n",
    "symbol_eval_list = [\n",
    "                        '^GSPC',\n",
    "                        '^DJI',\n",
    "                        '^IXIC',\n",
    "                        '^RUT',\n",
    "                        'XLC',\n",
    "                        'XLY',\n",
    "                        'XLP',\n",
    "                        'XLE',\n",
    "                        'XLF',\n",
    "                        'XLV',\n",
    "                        'XLI',\n",
    "                        'XLB',\n",
    "                        'XLRE',\n",
    "                        'XLK',\n",
    "                        'XLU',\n",
    "                        '^VIX',\n",
    "                        '^VIX3M',\n",
    "                        'CL=F',\n",
    "                        '^TNX',\n",
    "                        'BTC-USD',\n",
    "                        '^CMC200',\n",
    "                        ]\n",
    "\n",
    "symbol_result_list = ['SPY'\n",
    "                    , 'USO'\n",
    "                     ]\n",
    "\n",
    "input_symbol_01 = \"\"\n",
    "input_symbol_02 = \"\"\n",
    "input_symbol_03 = \"\"\n",
    "output_count = 0\n",
    "\n",
    "# Triple-loop through all of the symbol_eval_list and all of the symbol_result_list\n",
    "# and determine all possible combinations. Write all combos to a list. \n",
    "# Then auto-run machine learning neural networks for each\n",
    "# one of them by looping through the list that was created.\n",
    "# Use the results to determine best candidates for further analysis.\n",
    "# The result is 420 unique combinations to test.\n",
    "\n",
    "# Outer loop through the smaller group of ticker symbols symbol_result_list\n",
    "for x3 in symbol_result_list:\n",
    "  input_symbol_03 = x3\n",
    "  pairings = []\n",
    "  for x1 in symbol_eval_list:\n",
    "    # Then get a ticker symbol from symbol_eval_list\n",
    "    input_symbol_01 = x1\n",
    "    for x2 in symbol_eval_list:\n",
    "      # get another symbol to pair up from ymbol_eval_list \n",
    "      input_symbol_02 = x2\n",
    "      # if the two symbols are not the same, proceed\n",
    "      if input_symbol_01 != input_symbol_02:\n",
    "        pairing_found = 'N'\n",
    "        # loop through the found pairings and check if that pairing already exists (also check the reverse order)\n",
    "        for i in range(len(pairings)):\n",
    "          if (pairing_found == 'N'):\n",
    "            if (pairings[i] == [x1, x2]) | (pairings[i] == [x2, x1]):\n",
    "              pairing_found = 'Y'\n",
    "        # if no pairing has already been writted out, we can process it, so write it now so it won't be processed again and then do all the procesing\n",
    "        if (pairing_found == 'N'):\n",
    "          pairings.append([x1, x2])\n",
    "          print(f\"BEGIN PROCESS\")\n",
    "\n",
    "          # Load ticker1 historical data from Yahoo Finance API\n",
    "          today = date.today()\n",
    "          curr_date = today.strftime(\"%m/%d/%Y\")\n",
    "          df_01 = get_data(input_symbol_01, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_01_min_date = (df_01.iloc[0][\"date\"])\n",
    "\n",
    "          # Load ticker2 historical data from Yahoo Finance API\n",
    "          from datetime import date\n",
    "          today = date.today()\n",
    "          curr_date = today.strftime(\"%m/%d/%Y\")\n",
    "          df_02 = get_data(input_symbol_02, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_02_min_date = (df_02.iloc[0][\"date\"])\n",
    "\n",
    "          # Load ticker3 historical data from Yahoo Finance API\n",
    "          from datetime import date\n",
    "          today = date.today()\n",
    "          curr_date = today.strftime(\"%m/%d/%Y\")\n",
    "          df_03 = get_data(input_symbol_03, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_03_min_date = (df_03.iloc[0][\"date\"])\n",
    "\n",
    "          # Find the first date in each dataframe and get the latest date, that way all dataframes start on the same date when concatinated\n",
    "          latest_date = df_01_min_date\n",
    "          if df_02_min_date > latest_date:\n",
    "            latest_date = df_02_min_date\n",
    "          if df_03_min_date > latest_date:\n",
    "            latest_date = df_03_min_date\n",
    "          print(f\"latest_date: {latest_date}\")\n",
    "          df_01 = df_01[df_01.date >= latest_date]\n",
    "          df_02 = df_02[df_02.date >= latest_date]\n",
    "          df_03 = df_03[df_03.date >= latest_date]\n",
    "          \n",
    "          output_count+=1\n",
    "          print(f\"OUTPUT COUNT: {output_count}\")\n",
    "          # set the column names for this run, based on the ticker symbols\n",
    "          col01 = (f\"{input_symbol_01}_close\")\n",
    "          col02 = (f\"{input_symbol_02}_close\")\n",
    "          col03 = (f\"{input_symbol_03}_close\")\n",
    "\n",
    "          # clean and merge the 3 dataframes, and add some new cols\n",
    "          df = df_01[['date', 'close']].copy()\n",
    "          df = df.rename(columns={'close': col01})\n",
    "          df = df.merge(df_02, on='date')\n",
    "          df = df.rename(columns={'close': col02})\n",
    "          df = df.drop(columns=['open', 'high', 'low', 'adjclose', 'volume', 'ticker'])\n",
    "          df[input_symbol_01+'_percentage'] = \"\"\n",
    "          df[input_symbol_02+'_percentage'] = \"\"\n",
    "          df[input_symbol_01+'_percentage_boolean'] = \"\"\n",
    "          df[input_symbol_02+'_percentage_boolean'] = \"\"\n",
    "#           df['reversion_boolean'] = \"\"\n",
    "          df = df.merge(df_03, on='date')\n",
    "          df = df.rename(columns={'close': col03})\n",
    "          df = df.drop(columns=['open', 'high', 'low', 'adjclose', 'volume', 'ticker'])\n",
    "          df[input_symbol_03+'_future_result'] = \"\"\n",
    "          df[input_symbol_03+'_future_result_boolean'] = \"\"\n",
    "\n",
    "          # loop through the df to populate the new columns\n",
    "          for i in range(len(df)):\n",
    "            if (i < (len(df))):\n",
    "                if (i > (days_looking_back-1)):\n",
    "                    \n",
    "                    df[input_symbol_01+'_percentage'][i] = ((df[col01][i]) - (df[col01][i-days_looking_back])) / (df[col01][i-days_looking_back])\n",
    "                    if (df[input_symbol_01+'_percentage'][i] != \"\" ):\n",
    "                        if (df[input_symbol_01+'_percentage'][i] > 0 ):\n",
    "                            df[input_symbol_01+'_percentage_boolean'][i] = 1\n",
    "                        else:\n",
    "                            df[input_symbol_01+'_percentage_boolean'][i] = 0\n",
    "                            \n",
    "                    df[input_symbol_02+'_percentage'][i] = ((df[col02][i]) - (df[col02][i-days_looking_back])) / (df[col02][i-days_looking_back])\n",
    "                    if (df[input_symbol_02+'_percentage'][i] != \"\" ):\n",
    "                        if (df[input_symbol_02+'_percentage'][i] > 0 ):\n",
    "                            df[input_symbol_02+'_percentage_boolean'][i] = 1\n",
    "                        else:\n",
    "                            df[input_symbol_02+'_percentage_boolean'][i] = 0\n",
    "            if (i < (len(df)-days_in_future_that_result_is_calculated)):\n",
    "              df[input_symbol_03+'_future_result'][i] = ((df[col03][i+days_in_future_that_result_is_calculated]-df[col03][i])/df[col03][i])\n",
    "   \n",
    "\n",
    "          df = df[df[input_symbol_03+'_future_result'] != \"\"]\n",
    "\n",
    "            \n",
    "          # For the model, pick which cols will be fed into 'X' as inputs\n",
    "          input_column_list_for_X = [\n",
    "            input_symbol_01+\"_percentage_boolean\"\n",
    "            ,\n",
    "            input_symbol_02+\"_percentage_boolean\"\n",
    "\n",
    "            ]\n",
    "          print (f\"input_column_list_for_X: {input_column_list_for_X}\")\n",
    "\n",
    "          # For the model, pick which col will be the 'y' result\n",
    "          output_col_for_y = [\n",
    "              # \"future_result\"\n",
    "              input_symbol_03+\"_future_result_boolean\"\n",
    "              ]\n",
    "          print (f\"output_col_for_y: {output_col_for_y}\")\n",
    "\n",
    "        # make sure numeric\n",
    "          df[input_symbol_03+\"_future_result\"] = pd.to_numeric(df[input_symbol_03+\"_future_result\"])\n",
    "\n",
    "        # set more new cols\n",
    "          for i in range(len(df)):\n",
    "#               if (df[input_symbol_03+'_future_result'][i] != \"\" ):\n",
    "                  if (df[input_symbol_03+'_future_result'][i] > 0):\n",
    "                    df[input_symbol_03+'_future_result_boolean'][i] = 1\n",
    "                  else:\n",
    "                    df[input_symbol_03+'_future_result_boolean'][i] = 0\n",
    "\n",
    "          df[input_symbol_03+\"_future_result_boolean\"] = pd.to_numeric(df[input_symbol_03+\"_future_result_boolean\"])\n",
    "\n",
    "          df = df[df[input_symbol_01+'_percentage'] != \"\"]\n",
    "          df = df[df[input_symbol_02+'_percentage'] != \"\"]\n",
    "        \n",
    "        # make sure numeric\n",
    "          df[input_symbol_01+'_percentage'] = pd.to_numeric(df[input_symbol_01+'_percentage'])\n",
    "          df[input_symbol_01+'_percentage_boolean'] = pd.to_numeric(df[input_symbol_01+'_percentage_boolean'])\n",
    "          df[input_symbol_02+'_percentage'] = pd.to_numeric(df[input_symbol_02+'_percentage'])\n",
    "          df[input_symbol_02+'_percentage_boolean'] = pd.to_numeric(df[input_symbol_02+'_percentage_boolean'])\n",
    "\n",
    "            \n",
    "            \n",
    "          # Remove target 'y' from features data\n",
    "          y = df[output_col_for_y].values\n",
    "\n",
    "          # Pick columns to use for input 'X'\n",
    "          X = df[input_column_list_for_X].values\n",
    "\n",
    "          # Split the preprocessed data into a training and testing dataset\n",
    "          X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "          # Create a StandardScaler instances\n",
    "          scaler = StandardScaler()\n",
    "\n",
    "          # Fit the StandardScaler\n",
    "          X_scaler = scaler.fit(X_train)\n",
    "\n",
    "          # Scale the data\n",
    "          if scale_data == \"N\":\n",
    "            import numpy as np\n",
    "            X_train = np.asarray(X_train).astype(np.float64)\n",
    "            X_train_scaled = X_train\n",
    "            X_test = np.asarray(X_test).astype(np.float64)\n",
    "            X_test_scaled = X_test\n",
    "          else:\n",
    "            X_train_scaled = X_scaler.transform(X_train)\n",
    "            X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "          # Compile, Train and Evaluate the Model\n",
    "\n",
    "          number_input_features = len(X_train[0])\n",
    "\n",
    "          nn = tf.keras.models.Sequential()\n",
    "\n",
    "          # First hidden layer\n",
    "          hidden_nodes_layer1 = num_nodes\n",
    "          nn.add(\n",
    "              tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_type)\n",
    "          )\n",
    "          if num_layers >= 2:\n",
    "            # second hidden layer\n",
    "            hidden_nodes_layer2 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=activation_type))\n",
    "          if num_layers >= 3:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer3 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=activation_type))\n",
    "          if num_layers >= 4:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer4 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=activation_type))\n",
    "          if num_layers >= 5:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer5 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=activation_type))\n",
    "          if num_layers >= 6:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer6 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=activation_type))\n",
    "          if num_layers >= 7:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer7 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer7, activation=activation_type))\n",
    "          if num_layers >= 8:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer8 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer8, activation=activation_type))\n",
    "          if num_layers >= 9:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer9 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer9, activation=activation_type))\n",
    "          if num_layers >= 10:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer10 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer10, activation=activation_type))\n",
    "\n",
    "          # Output layer\n",
    "          nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "          # Check the structure of the model\n",
    "          nn.summary()\n",
    "\n",
    "          # Compile the model\n",
    "          nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "          # Train the model\n",
    "          fit_model = nn.fit(X_train_scaled,y_train,epochs=num_epochs)\n",
    "\n",
    "          # Evaluate the model using the test data\n",
    "          model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "\n",
    "          # Need to document well the RESULTS from EACH run - this output will be just one of hundreds of loops in the output\n",
    "          print(f\"RESULTS\")\n",
    "          print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "          print(f\"Symbol 01: {input_symbol_01}\")\n",
    "          print(f\"Symbol 02: {input_symbol_02}\")\n",
    "          print(f\"Symbol 03: {input_symbol_03}\")\n",
    "          print(f\"Scale Data = {scale_data}\")\n",
    "          print(f\"activation_type = {activation_type}\")\n",
    "          print(f\"num_epochs = {num_epochs}\")\n",
    "          print(f\"num_layers = {num_layers}\")\n",
    "          print(f\"Layer 1 Nodes = {hidden_nodes_layer1}\")\n",
    "          if num_layers >= 2:\n",
    "            print(f\"Layer 2 Nodes = {hidden_nodes_layer2}\")\n",
    "          if num_layers >= 3:\n",
    "            print(f\"Layer 3 Nodes: {hidden_nodes_layer3}\")\n",
    "          if num_layers >= 4:\n",
    "            print(f\"Layer 4 Nodes = {hidden_nodes_layer4}\")\n",
    "          if num_layers >= 5:\n",
    "            print(f\"Layer 5 Nodes = {hidden_nodes_layer5}\")\n",
    "          if num_layers >= 6:\n",
    "            print(f\"Layer 6 Nodes = {hidden_nodes_layer6}\")\n",
    "          if num_layers >= 7:\n",
    "            print(f\"Layer 7 Nodes = {hidden_nodes_layer7}\")\n",
    "          if num_layers >= 8:\n",
    "            print(f\"Layer 8 Nodes = {hidden_nodes_layer8}\")\n",
    "          if num_layers >= 9:\n",
    "            print(f\"Layer 9 Nodes = {hidden_nodes_layer9}\")\n",
    "          if num_layers >= 10:\n",
    "            print(f\"Layer 10 Nodes = {hidden_nodes_layer10}\")\n",
    "          \n",
    "          print(\"\")\n",
    "          print(\"\")\n",
    "          print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>^GSPC_close</th>\n",
       "      <th>^DJI_close</th>\n",
       "      <th>^GSPC_percentage</th>\n",
       "      <th>^DJI_percentage</th>\n",
       "      <th>^GSPC_percentage_boolean</th>\n",
       "      <th>^DJI_percentage_boolean</th>\n",
       "      <th>SPY_close</th>\n",
       "      <th>SPY_future_result</th>\n",
       "      <th>SPY_future_result_boolean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>10997.929688</td>\n",
       "      <td>-0.038345</td>\n",
       "      <td>-0.031660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139.750000</td>\n",
       "      <td>-0.033989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>11122.650391</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.011340</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>-0.046094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>11253.259766</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.750000</td>\n",
       "      <td>-0.062160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>11522.559570</td>\n",
       "      <td>0.027090</td>\n",
       "      <td>0.023931</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145.750000</td>\n",
       "      <td>-0.106775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>1457.599976</td>\n",
       "      <td>11572.200195</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>146.250000</td>\n",
       "      <td>-0.112179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5717</th>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>3757.989990</td>\n",
       "      <td>30076.679688</td>\n",
       "      <td>-0.008428</td>\n",
       "      <td>-0.003548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>374.220001</td>\n",
       "      <td>0.155016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5718</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>3693.229980</td>\n",
       "      <td>29590.410156</td>\n",
       "      <td>-0.017233</td>\n",
       "      <td>-0.016168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>367.950012</td>\n",
       "      <td>0.157440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5719</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>3655.040039</td>\n",
       "      <td>29260.810547</td>\n",
       "      <td>-0.010341</td>\n",
       "      <td>-0.011139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364.309998</td>\n",
       "      <td>0.169471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>3647.290039</td>\n",
       "      <td>29134.990234</td>\n",
       "      <td>-0.002120</td>\n",
       "      <td>-0.004300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>363.380005</td>\n",
       "      <td>0.179261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>3719.040039</td>\n",
       "      <td>29683.740234</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.018835</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>370.529999</td>\n",
       "      <td>0.153699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5721 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  ^GSPC_close    ^DJI_close  ^GSPC_percentage  ^DJI_percentage  \\\n",
       "1    2000-01-04  1399.420044  10997.929688         -0.038345        -0.031660   \n",
       "2    2000-01-05  1402.109985  11122.650391          0.001922         0.011340   \n",
       "3    2000-01-06  1403.449951  11253.259766          0.000956         0.011743   \n",
       "4    2000-01-07  1441.469971  11522.559570          0.027090         0.023931   \n",
       "5    2000-01-10  1457.599976  11572.200195          0.011190         0.004308   \n",
       "...         ...          ...           ...               ...              ...   \n",
       "5717 2022-09-22  3757.989990  30076.679688         -0.008428        -0.003548   \n",
       "5718 2022-09-23  3693.229980  29590.410156         -0.017233        -0.016168   \n",
       "5719 2022-09-26  3655.040039  29260.810547         -0.010341        -0.011139   \n",
       "5720 2022-09-27  3647.290039  29134.990234         -0.002120        -0.004300   \n",
       "5721 2022-09-28  3719.040039  29683.740234          0.019672         0.018835   \n",
       "\n",
       "      ^GSPC_percentage_boolean  ^DJI_percentage_boolean   SPY_close  \\\n",
       "1                            0                        0  139.750000   \n",
       "2                            1                        1  140.000000   \n",
       "3                            1                        1  137.750000   \n",
       "4                            1                        1  145.750000   \n",
       "5                            1                        1  146.250000   \n",
       "...                        ...                      ...         ...   \n",
       "5717                         0                        0  374.220001   \n",
       "5718                         0                        0  367.950012   \n",
       "5719                         0                        0  364.309998   \n",
       "5720                         0                        0  363.380005   \n",
       "5721                         1                        1  370.529999   \n",
       "\n",
       "      SPY_future_result  SPY_future_result_boolean  \n",
       "1             -0.033989                          0  \n",
       "2             -0.046094                          0  \n",
       "3             -0.062160                          0  \n",
       "4             -0.106775                          0  \n",
       "5             -0.112179                          0  \n",
       "...                 ...                        ...  \n",
       "5717           0.155016                          1  \n",
       "5718           0.157440                          1  \n",
       "5719           0.169471                          1  \n",
       "5720           0.179261                          1  \n",
       "5721           0.153699                          1  \n",
       "\n",
       "[5721 rows x 10 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5724)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
