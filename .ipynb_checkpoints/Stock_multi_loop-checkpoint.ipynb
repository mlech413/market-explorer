{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "fh3PmurW-WFG"
   },
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRVDUu5nMiQk",
    "outputId": "f8214e1a-c902-4d4c-bb49-2e93fe1d1548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yahoo_fin in c:\\users\\mlech\\anaconda3\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: requests-html in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (0.10.0)\n",
      "Requirement already satisfied: feedparser in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (6.0.10)\n",
      "Requirement already satisfied: requests in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (2.28.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from yahoo_fin) (1.4.4)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from feedparser->yahoo_fin) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pandas->yahoo_fin) (1.23.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests->yahoo_fin) (2022.12.7)\n",
      "Requirement already satisfied: pyquery in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (2.0.0)\n",
      "Requirement already satisfied: fake-useragent in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.1.3)\n",
      "Requirement already satisfied: parse in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.19.0)\n",
      "Requirement already satisfied: bs4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (0.0.1)\n",
      "Requirement already satisfied: w3lib in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.21.0)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from requests-html->yahoo_fin) (1.0.2)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.11.3)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (8.2.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.64.1)\n",
      "Requirement already satisfied: websockets<11.0,>=10.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (10.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->yahoo_fin) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from bs4->requests-html->yahoo_fin) (4.11.1)\n",
      "Requirement already satisfied: importlib-resources>=5.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from fake-useragent->requests-html->yahoo_fin) (5.12.0)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyquery->requests-html->yahoo_fin) (4.9.1)\n",
      "Requirement already satisfied: cssselect>=1.2.0 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from pyquery->requests-html->yahoo_fin) (1.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests-html->yahoo_fin) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mlech\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4->requests-html->yahoo_fin) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yahoo_fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "6Mb-Apq5M02C"
   },
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AROMFS4N-jot",
    "outputId": "70855e4a-02ed-43bf-993c-8f84c90fe451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Days looking back for inputs that it is testing against: 1\n",
      "Days in the future that the result is calculated for:    5\n",
      "optimization_max_epochs: 5\n",
      "optimization_max_hidden_layers: 5\n",
      "df_GSPC loaded\n",
      "df_DJI loaded\n",
      "df_IXIC loaded\n",
      "df_RUT loaded\n",
      "df_XLC loaded\n",
      "df_XLY loaded\n",
      "df_XLP loaded\n",
      "df_XLE loaded\n",
      "df_XLF loaded\n",
      "df_XLV loaded\n",
      "df_XLI loaded\n",
      "df_XLB loaded\n",
      "df_XLRE loaded\n",
      "df_XLK loaded\n",
      "df_XLU loaded\n",
      "df_VIX loaded\n",
      "df_VIX3M loaded\n",
      "df_TNX loaded\n",
      "df_BTC-USD loaded\n",
      "df_CMC200 loaded\n",
      "df_SPY loaded\n",
      "df_USO loaded\n",
      "BEGIN PROCESS\n",
      "latest_date: 2000-01-03 00:00:00\n",
      "OUTPUT COUNT: 1\n",
      "input_column_list_for_X: ['^GSPC_percentage_boolean', '^DJI_percentage_boolean']\n",
      "output_col_for_y: ['SPY_future_result_boolean']\n",
      "Model: \"sequential_503\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1507 (Dense)          (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_1508 (Dense)          (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_1509 (Dense)          (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51 (204.00 Byte)\n",
      "Trainable params: 51 (204.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 932us/step - loss: 0.6901 - accuracy: 0.5424\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 891us/step - loss: 0.6859 - accuracy: 0.5614\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 906us/step - loss: 0.6855 - accuracy: 0.5614\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 900us/step - loss: 0.6855 - accuracy: 0.5614\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 903us/step - loss: 0.6853 - accuracy: 0.5614\n",
      "47/47 - 0s - loss: 0.6809 - accuracy: 0.5845 - 153ms/epoch - 3ms/step\n",
      "RESULTS\n",
      "Loss: 0.6808534860610962, Accuracy: 0.5844504237174988\n",
      "Symbol 01: ^GSPC\n",
      "Symbol 02: ^DJI\n",
      "Symbol 03: SPY\n",
      "Scale Data = N\n",
      "activation_type = relu\n",
      "num_epochs = 5\n",
      "num_layers = 2\n",
      "Layer 1 Nodes = 5\n",
      "Layer 2 Nodes = 5\n",
      "\n",
      "\n",
      "\n",
      "BEGIN PROCESS\n",
      "latest_date: 2000-01-03 00:00:00\n",
      "OUTPUT COUNT: 2\n",
      "input_column_list_for_X: ['^GSPC_percentage_boolean', '^IXIC_percentage_boolean']\n",
      "output_col_for_y: ['SPY_future_result_boolean']\n",
      "Model: \"sequential_504\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1510 (Dense)          (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_1511 (Dense)          (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_1512 (Dense)          (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51 (204.00 Byte)\n",
      "Trainable params: 51 (204.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 927us/step - loss: 0.7120 - accuracy: 0.5025\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 970us/step - loss: 0.6910 - accuracy: 0.5139\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 898us/step - loss: 0.6861 - accuracy: 0.5614\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 898us/step - loss: 0.6854 - accuracy: 0.5614\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 884us/step - loss: 0.6854 - accuracy: 0.5614\n",
      "47/47 - 0s - loss: 0.6800 - accuracy: 0.5845 - 150ms/epoch - 3ms/step\n",
      "RESULTS\n",
      "Loss: 0.680044412612915, Accuracy: 0.5844504237174988\n",
      "Symbol 01: ^GSPC\n",
      "Symbol 02: ^IXIC\n",
      "Symbol 03: SPY\n",
      "Scale Data = N\n",
      "activation_type = relu\n",
      "num_epochs = 5\n",
      "num_layers = 2\n",
      "Layer 1 Nodes = 5\n",
      "Layer 2 Nodes = 5\n",
      "\n",
      "\n",
      "\n",
      "BEGIN PROCESS\n",
      "latest_date: 2000-01-03 00:00:00\n",
      "OUTPUT COUNT: 3\n",
      "input_column_list_for_X: ['^GSPC_percentage_boolean', '^RUT_percentage_boolean']\n",
      "output_col_for_y: ['SPY_future_result_boolean']\n",
      "Model: \"sequential_505\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1513 (Dense)          (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_1514 (Dense)          (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_1515 (Dense)          (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51 (204.00 Byte)\n",
      "Trainable params: 51 (204.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 961us/step - loss: 0.6950 - accuracy: 0.5395\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 905us/step - loss: 0.6884 - accuracy: 0.5498\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 900us/step - loss: 0.6868 - accuracy: 0.5614\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 877us/step - loss: 0.6864 - accuracy: 0.5614\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 920us/step - loss: 0.6861 - accuracy: 0.5614\n",
      "47/47 - 0s - loss: 0.6808 - accuracy: 0.5845 - 153ms/epoch - 3ms/step\n",
      "RESULTS\n",
      "Loss: 0.6807708740234375, Accuracy: 0.5844504237174988\n",
      "Symbol 01: ^GSPC\n",
      "Symbol 02: ^RUT\n",
      "Symbol 03: SPY\n",
      "Scale Data = N\n",
      "activation_type = relu\n",
      "num_epochs = 5\n",
      "num_layers = 2\n",
      "Layer 1 Nodes = 5\n",
      "Layer 2 Nodes = 5\n",
      "\n",
      "\n",
      "\n",
      "BEGIN PROCESS\n",
      "latest_date: 2018-06-19 00:00:00\n",
      "OUTPUT COUNT: 4\n",
      "input_column_list_for_X: ['^GSPC_percentage_boolean', 'XLC_percentage_boolean']\n",
      "output_col_for_y: ['SPY_future_result_boolean']\n",
      "Model: \"sequential_506\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1516 (Dense)          (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_1517 (Dense)          (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_1518 (Dense)          (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51 (204.00 Byte)\n",
      "Trainable params: 51 (204.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 948us/step - loss: 0.6891 - accuracy: 0.5891\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 951us/step - loss: 0.6853 - accuracy: 0.6002\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.6022\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 982us/step - loss: 0.6812 - accuracy: 0.6022\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 943us/step - loss: 0.6794 - accuracy: 0.6022\n",
      "11/11 - 0s - loss: 0.6788 - accuracy: 0.5861 - 141ms/epoch - 13ms/step\n",
      "RESULTS\n",
      "Loss: 0.6787732839584351, Accuracy: 0.5861027240753174\n",
      "Symbol 01: ^GSPC\n",
      "Symbol 02: XLC\n",
      "Symbol 03: SPY\n",
      "Scale Data = N\n",
      "activation_type = relu\n",
      "num_epochs = 5\n",
      "num_layers = 2\n",
      "Layer 1 Nodes = 5\n",
      "Layer 2 Nodes = 5\n",
      "\n",
      "\n",
      "\n",
      "BEGIN PROCESS\n",
      "latest_date: 2000-01-03 00:00:00\n",
      "OUTPUT COUNT: 5\n",
      "input_column_list_for_X: ['^GSPC_percentage_boolean', 'XLY_percentage_boolean']\n",
      "output_col_for_y: ['SPY_future_result_boolean']\n",
      "Model: \"sequential_507\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_1519 (Dense)          (None, 5)                 15        \n",
      "                                                                 \n",
      " dense_1520 (Dense)          (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_1521 (Dense)          (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51 (204.00 Byte)\n",
      "Trainable params: 51 (204.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 1s 930us/step - loss: 0.6894 - accuracy: 0.5610\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 921us/step - loss: 0.6864 - accuracy: 0.5614\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 898us/step - loss: 0.6860 - accuracy: 0.5614\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 895us/step - loss: 0.6858 - accuracy: 0.5614\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 895us/step - loss: 0.6857 - accuracy: 0.5614\n",
      "47/47 - 0s - loss: 0.6817 - accuracy: 0.5845 - 155ms/epoch - 3ms/step\n",
      "RESULTS\n",
      "Loss: 0.6817059516906738, Accuracy: 0.5844504237174988\n",
      "Symbol 01: ^GSPC\n",
      "Symbol 02: XLY\n",
      "Symbol 03: SPY\n",
      "Scale Data = N\n",
      "activation_type = relu\n",
      "num_epochs = 5\n",
      "num_layers = 2\n",
      "Layer 1 Nodes = 5\n",
      "Layer 2 Nodes = 5\n",
      "\n",
      "\n",
      "\n",
      "BEGIN PROCESS\n",
      "latest_date: 2000-01-03 00:00:00\n",
      "OUTPUT COUNT: 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20876\\2384951628.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    207\u001b[0m                             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_symbol_01\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_percentage_boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m                             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_symbol_01\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_percentage_boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_symbol_02\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_percentage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol02\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol02\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdays_looking_back\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol02\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdays_looking_back\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy, inplace)\u001b[0m\n\u001b[0;32m   1277\u001b[0m                 \u001b[1;31m# to ensure column still in dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m                 \u001b[1;31m# otherwise, either self or ref has swapped in new arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1279\u001b[1;33m                 \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1280\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1281\u001b[0m                 \u001b[1;31m# GH#33675 we have swapped in a new array, so parent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[1;34m(self, item, value, inplace)\u001b[0m\n\u001b[0;32m   3954\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3956\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3957\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3958\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36miset\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Accessing public blknos ensures the public versions are initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mblknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mblklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[0munfit_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# ***************************\n",
    "# ***                     ***\n",
    "# ***    SET VARIABLES    ***\n",
    "# ***                     ***\n",
    "# ***************************\n",
    "\n",
    "days_looking_back = 1\n",
    "print(f\"Days looking back for inputs that it is testing against: {days_looking_back}\")\n",
    "\n",
    "days_in_future_that_result_is_calculated = 5\n",
    "print(f\"Days in the future that the result is calculated for:    {days_in_future_that_result_is_calculated}\")\n",
    "\n",
    "# reversion_low_value = 12\n",
    "# print(f\"reversion_low_value: {reversion_low_value}\")\n",
    "\n",
    "# reversion_high_value = 20\n",
    "# print(f\"reversion_high_value: {reversion_high_value}\")\n",
    "\n",
    "optimization_max_epochs = 5\n",
    "print(f\"optimization_max_epochs: {optimization_max_epochs}\")\n",
    "\n",
    "# Max 10:\n",
    "optimization_max_hidden_layers = 5\n",
    "print(f\"optimization_max_hidden_layers: {optimization_max_hidden_layers}\")\n",
    "\n",
    "optimization_max_nodes = 5\n",
    "\n",
    "\n",
    "activation_type = 'relu'\n",
    "\n",
    "# Max 10:\n",
    "num_layers = 2\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "num_nodes = 5\n",
    "\n",
    "\n",
    "# SCALE THE DATA? \"Y\" or \"N\":\n",
    "scale_data = \"N\"\n",
    "\n",
    "\n",
    "# TICKER SYMBOLS TO PROCESS:\n",
    "\n",
    "# 21 symbols to pair up, plus 2 result tickers to test output,\n",
    "# so 210 unique pairs * 2 outputs = 420 combinations are \n",
    "# looped through and be tested\n",
    "\n",
    "symbol_eval_list = [\n",
    "                        '^GSPC'\n",
    "                       , '^DJI'\n",
    "                       , '^IXIC'\n",
    "                       ,'^RUT'\n",
    "                       , 'XLC'\n",
    "                       , 'XLY'\n",
    "                       , 'XLP'\n",
    "                       , 'XLE'\n",
    "                       , 'XLF'\n",
    "                       , 'XLV'\n",
    "                       , 'XLI'\n",
    "                       , 'XLB'\n",
    "                       , 'XLRE'\n",
    "                       , 'XLK'\n",
    "                       , 'XLU'\n",
    "                       , '^VIX'\n",
    "                       , '^VIX3M'\n",
    "                       ,'^TNX'\n",
    "                       ,'BTC-USD'\n",
    "                       ,'^CMC200'\n",
    "                        ]\n",
    "\n",
    "symbol_result_list = ['SPY'\n",
    "                    , 'USO'\n",
    "                     ]\n",
    "\n",
    "input_symbol_01 = \"\"\n",
    "input_symbol_02 = \"\"\n",
    "input_symbol_03 = \"\"\n",
    "output_count = 0\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "curr_date = today.strftime(\"%m/%d/%Y\")\n",
    "        \n",
    "    \n",
    "# Create and polulate dataframes for each symbol \n",
    "for symbol_name in symbol_eval_list:\n",
    "    symbol_simple = symbol_name\n",
    "    if (symbol_simple[0] == '^'):\n",
    "        symbol_simple = symbol_simple[1:]\n",
    "    # Load each historical data from Yahoo Finance API\n",
    "    locals()['df_' + symbol_simple]  = get_data(symbol_name, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "    df_name = ('df_' + symbol_simple)\n",
    "    print (f\"{df_name} loaded\")\n",
    "\n",
    "for symbol_name in symbol_result_list:\n",
    "    symbol_simple = symbol_name\n",
    "    if (symbol_simple[0] == '^'):\n",
    "        symbol_simple = symbol_simple[1:]\n",
    "    # Load each historical data from Yahoo Finance API\n",
    "    globals()['df_' + symbol_simple]  = get_data(symbol_name, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "    df_name = ('df_' + symbol_simple)\n",
    "    print (f\"{df_name} loaded\")\n",
    "\n",
    "    \n",
    "# Triple-loop through all of the symbol_eval_list and all of the symbol_result_list\n",
    "# and determine all possible combinations. Write all combos to a list. \n",
    "# Then auto-run machine learning neural networks for each\n",
    "# one of them by looping through the list that was created.\n",
    "# Use the results to determine best candidates for further analysis.\n",
    "# The result is 420 unique combinations to test.\n",
    "\n",
    "# Outer loop through the smaller group of ticker symbols symbol_result_list\n",
    "for x3 in symbol_result_list:\n",
    "  input_symbol_03 = x3\n",
    "  symbol_simple_03 = x3\n",
    "  if (symbol_simple_03[0] == '^'):\n",
    "    symbol_simple_03 = symbol_simple_03[1:]\n",
    "  pairings = []\n",
    "  for x1 in symbol_eval_list:\n",
    "    # Then get a ticker symbol from symbol_eval_list\n",
    "    input_symbol_01 = x1\n",
    "    symbol_simple_01 = x1\n",
    "    if (symbol_simple_01[0] == '^'):\n",
    "        symbol_simple_01 = symbol_simple_01[1:]\n",
    "    for x2 in symbol_eval_list:\n",
    "      # get another symbol to pair up from ymbol_eval_list \n",
    "      input_symbol_02 = x2\n",
    "      symbol_simple_02 = x2\n",
    "      if (symbol_simple_02[0] == '^'):\n",
    "          symbol_simple_02 = symbol_simple_02[1:]\n",
    "      # if the two symbols are not the same, proceed\n",
    "      if input_symbol_01 != input_symbol_02:\n",
    "        pairing_found = 'N'\n",
    "        # loop through the found pairings and check if that pairing already exists (also check the reverse order)\n",
    "        for i in range(len(pairings)):\n",
    "          if (pairing_found == 'N'):\n",
    "            if (pairings[i] == [x1, x2]) | (pairings[i] == [x2, x1]):\n",
    "              pairing_found = 'Y'\n",
    "        # if no pairing has already been writted out, we can process it, so write it now so it won't be processed again and then do all the procesing\n",
    "        if (pairing_found == 'N'):\n",
    "          pairings.append([x1, x2])\n",
    "          print(f\"BEGIN PROCESS\")\n",
    "          # Load ticker1 historical data from Yahoo Finance API\n",
    "          df_name = ('df_' + symbol_simple_01)\n",
    "          df_01 = globals()['df_' + symbol_simple_01].copy()\n",
    "#           df_01 = get_data(input_symbol_01, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_01_min_date = (df_01.iloc[0][\"date\"])\n",
    "          \n",
    "\n",
    "          # Load ticker2 historical data from Yahoo Finance API\n",
    "          df_02 = globals()['df_' + symbol_simple_02].copy()\n",
    "#           df_02 = get_data(input_symbol_02, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_02_min_date = (df_02.iloc[0][\"date\"])\n",
    "          \n",
    "\n",
    "          # Load ticker3 historical data from Yahoo Finance API\n",
    "          df_03 = globals()['df_' + symbol_simple_03].copy()\n",
    "#           df_03 = get_data(input_symbol_03, start_date=\"01/01/2000\", end_date=curr_date, index_as_date = False, interval=\"1d\")\n",
    "          df_03_min_date = (df_03.iloc[0][\"date\"])\n",
    "\n",
    "\n",
    "          # Find the first date in each dataframe and get the latest date, that way all dataframes start on the same date when concatinated\n",
    "          latest_date = df_01_min_date\n",
    "          if df_02_min_date > latest_date:\n",
    "            latest_date = df_02_min_date\n",
    "          if df_03_min_date > latest_date:\n",
    "            latest_date = df_03_min_date\n",
    "          print(f\"latest_date: {latest_date}\")\n",
    "          df_01 = df_01[df_01.date >= latest_date]\n",
    "          df_02 = df_02[df_02.date >= latest_date]\n",
    "          df_03 = df_03[df_03.date >= latest_date]\n",
    "          \n",
    "          output_count+=1\n",
    "          print(f\"OUTPUT COUNT: {output_count}\")\n",
    "          # set the column names for this run, based on the ticker symbols\n",
    "          col01 = (f\"{input_symbol_01}_close\")\n",
    "          col02 = (f\"{input_symbol_02}_close\")\n",
    "          col03 = (f\"{input_symbol_03}_close\")\n",
    "\n",
    "          # clean and merge the 3 dataframes, and add some new cols\n",
    "          df = df_01[['date', 'close']].copy()\n",
    "          df = df.rename(columns={'close': col01})\n",
    "          df = df.merge(df_02, on='date')\n",
    "          df = df.rename(columns={'close': col02})\n",
    "          df = df.drop(columns=['open', 'high', 'low', 'adjclose', 'volume', 'ticker'])\n",
    "          df[input_symbol_01+'_percentage'] = \"\"\n",
    "          df[input_symbol_02+'_percentage'] = \"\"\n",
    "          df[input_symbol_01+'_percentage_boolean'] = \"\"\n",
    "          df[input_symbol_02+'_percentage_boolean'] = \"\"\n",
    "#           df['reversion_boolean'] = \"\"\n",
    "          df = df.merge(df_03, on='date')\n",
    "          df = df.rename(columns={'close': col03})\n",
    "          df = df.drop(columns=['open', 'high', 'low', 'adjclose', 'volume', 'ticker'])\n",
    "          df[input_symbol_03+'_future_result'] = \"\"\n",
    "          df[input_symbol_03+'_future_result_boolean'] = \"\"\n",
    "\n",
    "          # loop through the df to populate the new columns\n",
    "          for i in range(len(df)):\n",
    "            if (i < (len(df))):\n",
    "                if (i > (days_looking_back-1)):\n",
    "                    \n",
    "                    df[input_symbol_01+'_percentage'][i] = ((df[col01][i]) - (df[col01][i-days_looking_back])) / (df[col01][i-days_looking_back])\n",
    "                    if (df[input_symbol_01+'_percentage'][i] != \"\" ):\n",
    "                        if (df[input_symbol_01+'_percentage'][i] > 0 ):\n",
    "                            df[input_symbol_01+'_percentage_boolean'][i] = 1\n",
    "                        else:\n",
    "                            df[input_symbol_01+'_percentage_boolean'][i] = 0\n",
    "                            \n",
    "                    df[input_symbol_02+'_percentage'][i] = ((df[col02][i]) - (df[col02][i-days_looking_back])) / (df[col02][i-days_looking_back])\n",
    "                    if (df[input_symbol_02+'_percentage'][i] != \"\" ):\n",
    "                        if (df[input_symbol_02+'_percentage'][i] > 0 ):\n",
    "                            df[input_symbol_02+'_percentage_boolean'][i] = 1\n",
    "                        else:\n",
    "                            df[input_symbol_02+'_percentage_boolean'][i] = 0\n",
    "            if (i < (len(df)-days_in_future_that_result_is_calculated)):\n",
    "              df[input_symbol_03+'_future_result'][i] = ((df[col03][i+days_in_future_that_result_is_calculated]-df[col03][i])/df[col03][i])\n",
    "   \n",
    "\n",
    "          df = df[df[input_symbol_03+'_future_result'] != \"\"]\n",
    "\n",
    "            \n",
    "          # For the model, pick which cols will be fed into 'X' as inputs\n",
    "          input_column_list_for_X = [\n",
    "            input_symbol_01+\"_percentage_boolean\"\n",
    "            ,\n",
    "            input_symbol_02+\"_percentage_boolean\"\n",
    "\n",
    "            ]\n",
    "          print (f\"input_column_list_for_X: {input_column_list_for_X}\")\n",
    "\n",
    "          # For the model, pick which col will be the 'y' result\n",
    "          output_col_for_y = [\n",
    "              # \"future_result\"\n",
    "              input_symbol_03+\"_future_result_boolean\"\n",
    "              ]\n",
    "          print (f\"output_col_for_y: {output_col_for_y}\")\n",
    "\n",
    "        # make sure numeric\n",
    "          df[input_symbol_03+\"_future_result\"] = pd.to_numeric(df[input_symbol_03+\"_future_result\"])\n",
    "\n",
    "        # set more new cols\n",
    "          for i in range(len(df)):\n",
    "#               if (df[input_symbol_03+'_future_result'][i] != \"\" ):\n",
    "                  if (df[input_symbol_03+'_future_result'][i] > 0):\n",
    "                    df[input_symbol_03+'_future_result_boolean'][i] = 1\n",
    "                  else:\n",
    "                    df[input_symbol_03+'_future_result_boolean'][i] = 0\n",
    "\n",
    "          df[input_symbol_03+\"_future_result_boolean\"] = pd.to_numeric(df[input_symbol_03+\"_future_result_boolean\"])\n",
    "\n",
    "          df = df[df[input_symbol_01+'_percentage'] != \"\"]\n",
    "          df = df[df[input_symbol_02+'_percentage'] != \"\"]\n",
    "        \n",
    "        # make sure numeric\n",
    "          df[input_symbol_01+'_percentage'] = pd.to_numeric(df[input_symbol_01+'_percentage'])\n",
    "          df[input_symbol_01+'_percentage_boolean'] = pd.to_numeric(df[input_symbol_01+'_percentage_boolean'])\n",
    "          df[input_symbol_02+'_percentage'] = pd.to_numeric(df[input_symbol_02+'_percentage'])\n",
    "          df[input_symbol_02+'_percentage_boolean'] = pd.to_numeric(df[input_symbol_02+'_percentage_boolean'])\n",
    "\n",
    "            \n",
    "            \n",
    "          # Remove target 'y' from features data\n",
    "          y = df[output_col_for_y].values\n",
    "\n",
    "          # Pick columns to use for input 'X'\n",
    "          X = df[input_column_list_for_X].values\n",
    "\n",
    "          # Split the preprocessed data into a training and testing dataset\n",
    "          X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "          # Create a StandardScaler instances\n",
    "          scaler = StandardScaler()\n",
    "\n",
    "          # Fit the StandardScaler\n",
    "          X_scaler = scaler.fit(X_train)\n",
    "\n",
    "          # Scale the data\n",
    "          if scale_data == \"N\":\n",
    "            import numpy as np\n",
    "            X_train = np.asarray(X_train).astype(np.float64)\n",
    "            X_train_scaled = X_train\n",
    "            X_test = np.asarray(X_test).astype(np.float64)\n",
    "            X_test_scaled = X_test\n",
    "          else:\n",
    "            X_train_scaled = X_scaler.transform(X_train)\n",
    "            X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "          # Compile, Train and Evaluate the Model\n",
    "\n",
    "          number_input_features = len(X_train[0])\n",
    "\n",
    "          nn = tf.keras.models.Sequential()\n",
    "\n",
    "          # First hidden layer\n",
    "          hidden_nodes_layer1 = num_nodes\n",
    "          nn.add(\n",
    "              tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation_type)\n",
    "          )\n",
    "          if num_layers >= 2:\n",
    "            # second hidden layer\n",
    "            hidden_nodes_layer2 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=activation_type))\n",
    "          if num_layers >= 3:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer3 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=activation_type))\n",
    "          if num_layers >= 4:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer4 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=activation_type))\n",
    "          if num_layers >= 5:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer5 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=activation_type))\n",
    "          if num_layers >= 6:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer6 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=activation_type))\n",
    "          if num_layers >= 7:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer7 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer7, activation=activation_type))\n",
    "          if num_layers >= 8:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer8 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer8, activation=activation_type))\n",
    "          if num_layers >= 9:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer9 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer9, activation=activation_type))\n",
    "          if num_layers >= 10:\n",
    "            # hidden layer\n",
    "            hidden_nodes_layer10 = num_nodes\n",
    "            nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer10, activation=activation_type))\n",
    "\n",
    "          # Output layer\n",
    "          nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "          # Check the structure of the model\n",
    "          nn.summary()\n",
    "\n",
    "          # Compile the model\n",
    "          nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "          # Train the model\n",
    "          fit_model = nn.fit(X_train_scaled,y_train,epochs=num_epochs)\n",
    "\n",
    "          # Evaluate the model using the test data\n",
    "          model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "\n",
    "          # Need to document well the RESULTS from EACH run - this output will be just one of hundreds of loops in the output\n",
    "          print(f\"RESULTS\")\n",
    "          print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "          print(f\"Symbol 01: {input_symbol_01}\")\n",
    "          print(f\"Symbol 02: {input_symbol_02}\")\n",
    "          print(f\"Symbol 03: {input_symbol_03}\")\n",
    "          print(f\"Scale Data = {scale_data}\")\n",
    "          print(f\"activation_type = {activation_type}\")\n",
    "          print(f\"num_epochs = {num_epochs}\")\n",
    "          print(f\"num_layers = {num_layers}\")\n",
    "          print(f\"Layer 1 Nodes = {hidden_nodes_layer1}\")\n",
    "          if num_layers >= 2:\n",
    "            print(f\"Layer 2 Nodes = {hidden_nodes_layer2}\")\n",
    "          if num_layers >= 3:\n",
    "            print(f\"Layer 3 Nodes: {hidden_nodes_layer3}\")\n",
    "          if num_layers >= 4:\n",
    "            print(f\"Layer 4 Nodes = {hidden_nodes_layer4}\")\n",
    "          if num_layers >= 5:\n",
    "            print(f\"Layer 5 Nodes = {hidden_nodes_layer5}\")\n",
    "          if num_layers >= 6:\n",
    "            print(f\"Layer 6 Nodes = {hidden_nodes_layer6}\")\n",
    "          if num_layers >= 7:\n",
    "            print(f\"Layer 7 Nodes = {hidden_nodes_layer7}\")\n",
    "          if num_layers >= 8:\n",
    "            print(f\"Layer 8 Nodes = {hidden_nodes_layer8}\")\n",
    "          if num_layers >= 9:\n",
    "            print(f\"Layer 9 Nodes = {hidden_nodes_layer9}\")\n",
    "          if num_layers >= 10:\n",
    "            print(f\"Layer 10 Nodes = {hidden_nodes_layer10}\")\n",
    "          \n",
    "          print(\"\")\n",
    "          print(\"\")\n",
    "          print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-19</td>\n",
       "      <td>49.700001</td>\n",
       "      <td>50.060001</td>\n",
       "      <td>49.580002</td>\n",
       "      <td>49.959999</td>\n",
       "      <td>47.673180</td>\n",
       "      <td>16600</td>\n",
       "      <td>XLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-06-20</td>\n",
       "      <td>50.450001</td>\n",
       "      <td>50.889000</td>\n",
       "      <td>50.450001</td>\n",
       "      <td>50.580002</td>\n",
       "      <td>48.264797</td>\n",
       "      <td>190000</td>\n",
       "      <td>XLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-21</td>\n",
       "      <td>50.770000</td>\n",
       "      <td>50.849998</td>\n",
       "      <td>50.200001</td>\n",
       "      <td>50.270000</td>\n",
       "      <td>47.968987</td>\n",
       "      <td>428700</td>\n",
       "      <td>XLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>50.590000</td>\n",
       "      <td>50.610001</td>\n",
       "      <td>50.189999</td>\n",
       "      <td>50.490002</td>\n",
       "      <td>48.178921</td>\n",
       "      <td>181500</td>\n",
       "      <td>XLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-25</td>\n",
       "      <td>50.230000</td>\n",
       "      <td>50.230000</td>\n",
       "      <td>49.014999</td>\n",
       "      <td>49.450001</td>\n",
       "      <td>47.186527</td>\n",
       "      <td>2509600</td>\n",
       "      <td>XLC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       open       high        low      close   adjclose   volume  \\\n",
       "0 2018-06-19  49.700001  50.060001  49.580002  49.959999  47.673180    16600   \n",
       "1 2018-06-20  50.450001  50.889000  50.450001  50.580002  48.264797   190000   \n",
       "2 2018-06-21  50.770000  50.849998  50.200001  50.270000  47.968987   428700   \n",
       "3 2018-06-22  50.590000  50.610001  50.189999  50.490002  48.178921   181500   \n",
       "4 2018-06-25  50.230000  50.230000  49.014999  49.450001  47.186527  2509600   \n",
       "\n",
       "  ticker  \n",
       "0    XLC  \n",
       "1    XLC  \n",
       "2    XLC  \n",
       "3    XLC  \n",
       "4    XLC  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_XLC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
